{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiJLjXNJQ1ek"
      },
      "source": [
        "# UFC Fights:\n",
        "##Islam Makhachev VS Della Maddalena      |       Shevchenko VS Zhang\n",
        "\n",
        "###Author Ali & Abdirahman\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "events_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "Sf-a5HCxk0aO",
        "outputId": "f511f26a-3fd4-42ce-f872-2f08ac3e6535"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  f1_id f2_id            f1_name              f2_name            weight_class  \\\n",
              "0  3363  2768     cory sandhagen    umar nurmagomedov       Bantamweight Bout   \n",
              "1  2275  2800    shara magomedov  michal oleksiejczuk       Middleweight Bout   \n",
              "2  1576   299        jai herbert       rolando bedoya        Lightweight Bout   \n",
              "3  2648  2471  azamat murzakanov     alonzo menifield  Light Heavyweight Bout   \n",
              "4   997  3856    sedriques dumas      denis tiuliulin       Middleweight Bout   \n",
              "\n",
              "  f1_age_during f2_age_during f1_height_cm f2_height_cm f1_knockdowns  ...  \\\n",
              "0          32.0          28.0       180.34       172.72             0  ...   \n",
              "1          30.0          29.0       187.96       182.88             0  ...   \n",
              "2          36.0          27.0       185.42       180.34             1  ...   \n",
              "3          35.0          36.0        177.8       182.88             1  ...   \n",
              "4          28.0          36.0       187.96       185.42             0  ...   \n",
              "\n",
              "  str_def_diff td_avg_diff td_acc_diff td_def_diff sub_avg_diff stance_f1  \\\n",
              "0        -0.07       -2.79       -0.18       -0.37         -0.1    switch   \n",
              "1        -0.16       -1.08       -0.43        0.23          0.0  orthodox   \n",
              "2         0.00        0.50        0.23        0.26          0.0  orthodox   \n",
              "3         0.12       -0.01       -0.18        0.07         -0.2  southpaw   \n",
              "4         0.20        0.35       -0.07       -0.32          0.3  orthodox   \n",
              "\n",
              "  stance_f2        stance_matchup y_winner     reach_advantage  \n",
              "0  orthodox    switch_vs_orthodox        0     Small Advantage  \n",
              "1  southpaw  orthodox_vs_southpaw        1  Small Disadvantage  \n",
              "2  orthodox  orthodox_vs_orthodox        1     Large Advantage  \n",
              "3  orthodox  southpaw_vs_orthodox        1  Large Disadvantage  \n",
              "4  orthodox  orthodox_vs_orthodox        1     Large Advantage  \n",
              "\n",
              "[5 rows x 162 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f0fe2dc-4705-4034-9e46-03f033c682f7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1_id</th>\n",
              "      <th>f2_id</th>\n",
              "      <th>f1_name</th>\n",
              "      <th>f2_name</th>\n",
              "      <th>weight_class</th>\n",
              "      <th>f1_age_during</th>\n",
              "      <th>f2_age_during</th>\n",
              "      <th>f1_height_cm</th>\n",
              "      <th>f2_height_cm</th>\n",
              "      <th>f1_knockdowns</th>\n",
              "      <th>...</th>\n",
              "      <th>str_def_diff</th>\n",
              "      <th>td_avg_diff</th>\n",
              "      <th>td_acc_diff</th>\n",
              "      <th>td_def_diff</th>\n",
              "      <th>sub_avg_diff</th>\n",
              "      <th>stance_f1</th>\n",
              "      <th>stance_f2</th>\n",
              "      <th>stance_matchup</th>\n",
              "      <th>y_winner</th>\n",
              "      <th>reach_advantage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3363</td>\n",
              "      <td>2768</td>\n",
              "      <td>cory sandhagen</td>\n",
              "      <td>umar nurmagomedov</td>\n",
              "      <td>Bantamweight Bout</td>\n",
              "      <td>32.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>180.34</td>\n",
              "      <td>172.72</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-2.79</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.37</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>switch</td>\n",
              "      <td>orthodox</td>\n",
              "      <td>switch_vs_orthodox</td>\n",
              "      <td>0</td>\n",
              "      <td>Small Advantage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2275</td>\n",
              "      <td>2800</td>\n",
              "      <td>shara magomedov</td>\n",
              "      <td>michal oleksiejczuk</td>\n",
              "      <td>Middleweight Bout</td>\n",
              "      <td>30.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>187.96</td>\n",
              "      <td>182.88</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>-1.08</td>\n",
              "      <td>-0.43</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>orthodox</td>\n",
              "      <td>southpaw</td>\n",
              "      <td>orthodox_vs_southpaw</td>\n",
              "      <td>1</td>\n",
              "      <td>Small Disadvantage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1576</td>\n",
              "      <td>299</td>\n",
              "      <td>jai herbert</td>\n",
              "      <td>rolando bedoya</td>\n",
              "      <td>Lightweight Bout</td>\n",
              "      <td>36.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>185.42</td>\n",
              "      <td>180.34</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>orthodox</td>\n",
              "      <td>orthodox</td>\n",
              "      <td>orthodox_vs_orthodox</td>\n",
              "      <td>1</td>\n",
              "      <td>Large Advantage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2648</td>\n",
              "      <td>2471</td>\n",
              "      <td>azamat murzakanov</td>\n",
              "      <td>alonzo menifield</td>\n",
              "      <td>Light Heavyweight Bout</td>\n",
              "      <td>35.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>177.8</td>\n",
              "      <td>182.88</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.12</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>southpaw</td>\n",
              "      <td>orthodox</td>\n",
              "      <td>southpaw_vs_orthodox</td>\n",
              "      <td>1</td>\n",
              "      <td>Large Disadvantage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>997</td>\n",
              "      <td>3856</td>\n",
              "      <td>sedriques dumas</td>\n",
              "      <td>denis tiuliulin</td>\n",
              "      <td>Middleweight Bout</td>\n",
              "      <td>28.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>187.96</td>\n",
              "      <td>185.42</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.35</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.32</td>\n",
              "      <td>0.3</td>\n",
              "      <td>orthodox</td>\n",
              "      <td>orthodox</td>\n",
              "      <td>orthodox_vs_orthodox</td>\n",
              "      <td>1</td>\n",
              "      <td>Large Advantage</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 162 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f0fe2dc-4705-4034-9e46-03f033c682f7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f0fe2dc-4705-4034-9e46-03f033c682f7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f0fe2dc-4705-4034-9e46-03f033c682f7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fa50bb23-3ad8-400f-806d-d78cdfd14cec\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa50bb23-3ad8-400f-806d-d78cdfd14cec')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fa50bb23-3ad8-400f-806d-d78cdfd14cec button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "events_df"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "    import optuna\n",
        "except ImportError:\n",
        "    !pip install optuna\n",
        "    import optuna\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report\n",
        ")"
      ],
      "metadata": {
        "id": "88P3THTRBCQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e92ea62f-037a-4896-ab3b-50cbeda4360b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.1)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/404.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(fighters_path='ufc_fighters_avg.csv', events_path='ufc_fight_train - ufc_event_fight_stats.csv'):\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "\n",
        "    try:\n",
        "        fighters_df = pd.read_csv(fighters_path)\n",
        "        print(f\"Loaded fighters_df: {fighters_df.shape}\")\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Required file {fighters_path} not found. Please ensure the file is in the project directory.\")\n",
        "\n",
        "    try:\n",
        "        events_df = pd.read_csv(events_path)\n",
        "        print(f\"Loaded events_df: {events_df.shape}\")\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Required file {events_path} not found. Please ensure the file is in the project directory.\")\n",
        "\n",
        "    return fighters_df, events_df"
      ],
      "metadata": {
        "id": "eVErT_-yW1aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HQ9NZ0uEXhVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 - Data Cleaning"
      ],
      "metadata": {
        "id": "-G_sQh0-XlFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_fighters_df(fighters_df):\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"CLEANING FIGHTERS_DF\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"\\nShape: {fighters_df.shape}\")\n",
        "    print(f\"\\nDtypes:\\n{fighters_df.dtypes}\")\n",
        "    print(f\"\\nMissing values:\\n{fighters_df.isna().sum()}\")\n",
        "\n",
        "    fighters_df.columns = fighters_df.columns.str.strip().str.lower()\n",
        "\n",
        "    numeric_cols = fighters_df.select_dtypes(include=[np.number]).columns\n",
        "    for col in numeric_cols:\n",
        "        if fighters_df[col].isna().sum() > 0:\n",
        "            median_val = fighters_df[col].median()\n",
        "            fighters_df[col].fillna(median_val, inplace=True)\n",
        "            print(f\"Filled {col} with median: {median_val:.2f}\")\n",
        "\n",
        "    categorical_cols = fighters_df.select_dtypes(include=[object]).columns\n",
        "    for col in categorical_cols:\n",
        "        if fighters_df[col].isna().sum() > 0:\n",
        "            most_freq = fighters_df[col].mode()\n",
        "            fill_val = most_freq[0] if len(most_freq) > 0 else \"Unknown\"\n",
        "            fighters_df[col].fillna(fill_val, inplace=True)\n",
        "            print(f\"Filled {col} with: {fill_val}\")\n",
        "\n",
        "    if 'name' in fighters_df.columns:\n",
        "        fighters_df['name'] = fighters_df['name'].str.lower().str.strip()\n",
        "    if 'stance' in fighters_df.columns:\n",
        "        fighters_df['stance'] = fighters_df['stance'].str.lower().str.strip()\n",
        "        fighters_df['stance'] = fighters_df['stance'].replace('', 'unknown')\n",
        "\n",
        "    return fighters_df"
      ],
      "metadata": {
        "id": "CU2A-HIrXn0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_events_df(events_df):\n",
        "\n",
        "\n",
        "    events_df.columns = events_df.columns.str.strip().str.lower()\n",
        "\n",
        "    fighter_cols = [col for col in events_df.columns\n",
        "                   if any(term in col for term in ['fighter', 'f1', 'f2', 'red', 'blue', 'name'])]\n",
        "    print(f\"\\nFighter columns identified: {fighter_cols}\")\n",
        "\n",
        "    numeric_cols = events_df.select_dtypes(include=[np.number]).columns\n",
        "    for col in numeric_cols:\n",
        "        if events_df[col].isna().sum() > 0:\n",
        "            median_val = events_df[col].median()\n",
        "            events_df[col].fillna(median_val, inplace=True)\n",
        "\n",
        "    categorical_cols = events_df.select_dtypes(include=[object]).columns\n",
        "    for col in categorical_cols:\n",
        "        if events_df[col].isna().sum() > 0:\n",
        "            most_freq = events_df[col].mode()\n",
        "            fill_val = most_freq[0] if len(most_freq) > 0 else \"Unknown\"\n",
        "            events_df[col].fillna(fill_val, inplace=True)\n",
        "\n",
        "    for col in fighter_cols:\n",
        "        if col in events_df.columns:\n",
        "            events_df[col] = events_df[col].astype(str).str.lower().str.strip()\n",
        "\n",
        "    return events_df, fighter_cols"
      ],
      "metadata": {
        "id": "6mcbT0shXtbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_fighter_averages(events_df, fighters_df):\n",
        "\n",
        "    f1_name_col = None\n",
        "    f2_name_col = None\n",
        "\n",
        "    for col in events_df.columns:\n",
        "        if 'f1' in col and 'name' in col:\n",
        "            f1_name_col = col\n",
        "        elif 'f2' in col and 'name' in col:\n",
        "            f2_name_col = col\n",
        "        elif col == 'fighter1' or col == 'fighter1_name':\n",
        "            f1_name_col = col\n",
        "        elif col == 'fighter2' or col == 'fighter2_name':\n",
        "            f2_name_col = col\n",
        "\n",
        "    if f1_name_col is None:\n",
        "        fighter_cols = [col for col in events_df.columns if 'fighter' in col.lower()]\n",
        "        if len(fighter_cols) >= 1:\n",
        "            f1_name_col = fighter_cols[0]\n",
        "        if len(fighter_cols) >= 2:\n",
        "            f2_name_col = fighter_cols[1]\n",
        "\n",
        "    if f1_name_col is None or f2_name_col is None:\n",
        "        print(f\"Warning: Could not identify fighter name columns. Found: {f1_name_col}, {f2_name_col}\")\n",
        "        print(f\"Available columns: {list(events_df.columns)}\")\n",
        "        if f1_name_col is None:\n",
        "            f1_name_col = events_df.columns[0] if len(events_df.columns) > 0 else None\n",
        "        if f2_name_col is None:\n",
        "            f2_name_col = events_df.columns[1] if len(events_df.columns) > 1 else None\n",
        "\n",
        "    print(f\"Using f1_name_col: {f1_name_col}, f2_name_col: {f2_name_col}\")\n",
        "\n",
        "    fighters_name_col = None\n",
        "    for col in fighters_df.columns:\n",
        "        if 'name' in col.lower():\n",
        "            fighters_name_col = col\n",
        "            break\n",
        "\n",
        "    if fighters_name_col is None:\n",
        "        fighters_name_col = fighters_df.columns[0]\n",
        "\n",
        "    print(f\"Using fighters name column: {fighters_name_col}\")\n",
        "\n",
        "    if f1_name_col is None or f2_name_col is None:\n",
        "        raise ValueError(\"Could not identify fighter name columns for merging\")\n",
        "\n",
        "    assert f1_name_col is not None and f2_name_col is not None\n",
        "\n",
        "    f1_norm_col = f1_name_col + '_norm'\n",
        "    f2_norm_col = f2_name_col + '_norm'\n",
        "    fighters_norm_col = fighters_name_col + '_norm'\n",
        "\n",
        "    events_df[f1_norm_col] = events_df[f1_name_col].astype(str).str.lower().str.strip()\n",
        "    events_df[f2_norm_col] = events_df[f2_name_col].astype(str).str.lower().str.strip()\n",
        "    fighters_df[fighters_norm_col] = fighters_df[fighters_name_col].astype(str).str.lower().str.strip()\n",
        "\n",
        "    fighters_f1 = fighters_df.copy()\n",
        "    fighters_f1.columns = ['f1_' + col if col != fighters_name_col and col != fighters_norm_col else col for col in fighters_f1.columns]\n",
        "    events_df = events_df.merge(\n",
        "        fighters_f1,\n",
        "        left_on=f1_norm_col,\n",
        "        right_on=fighters_norm_col,\n",
        "        how='left',\n",
        "        suffixes=('', '_f1_merge')\n",
        "    )\n",
        "\n",
        "    fighters_f2 = fighters_df.copy()\n",
        "    fighters_f2.columns = ['f2_' + col if col != fighters_name_col and col != fighters_norm_col else col for col in fighters_f2.columns]\n",
        "    events_df = events_df.merge(\n",
        "        fighters_f2,\n",
        "        left_on=f2_norm_col,\n",
        "        right_on=fighters_norm_col,\n",
        "        how='left',\n",
        "        suffixes=('', '_f2_merge')\n",
        "    )\n",
        "\n",
        "    print(f\"After merge, shape: {events_df.shape}\")\n",
        "\n",
        "    f1_merged_col = None\n",
        "    f2_merged_col = None\n",
        "    for col in fighters_df.columns:\n",
        "        if col != fighters_name_col:\n",
        "            f1_merged_col = 'f1_' + col\n",
        "            f2_merged_col = 'f2_' + col\n",
        "            if f1_merged_col in events_df.columns:\n",
        "                break\n",
        "\n",
        "    if f1_merged_col and f1_merged_col in events_df.columns:\n",
        "        print(f\"Merge success rate f1: {events_df[f1_merged_col].notna().sum() / len(events_df):.2%}\")\n",
        "    else:\n",
        "        print(\"Merge success rate f1: Could not determine\")\n",
        "\n",
        "    if f2_merged_col and f2_merged_col in events_df.columns:\n",
        "        print(f\"Merge success rate f2: {events_df[f2_merged_col].notna().sum() / len(events_df):.2%}\")\n",
        "    else:\n",
        "        print(\"Merge success rate f2: Could not determine\")\n",
        "\n",
        "    return events_df"
      ],
      "metadata": {
        "id": "JPIeiS3SX7WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_pre_fight_features(events_df):\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"BUILDING PRE-FIGHT FEATURES\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    def safe_diff(f1_col, f2_col, default=0):\n",
        "        if f1_col in events_df.columns and f2_col in events_df.columns:\n",
        "            return events_df[f1_col] - events_df[f2_col]\n",
        "        else:\n",
        "            print(f\"Warning: {f1_col} or {f2_col} not found, using default {default}\")\n",
        "            return default\n",
        "\n",
        "    f1_age_col = None\n",
        "    f2_age_col = None\n",
        "    for col in events_df.columns:\n",
        "        if 'f1' in col.lower() and ('age' in col.lower() or 'age_during' in col.lower()):\n",
        "            f1_age_col = col\n",
        "        if 'f2' in col.lower() and ('age' in col.lower() or 'age_during' in col.lower()):\n",
        "            f2_age_col = col\n",
        "\n",
        "    f1_height_col = None\n",
        "    f2_height_col = None\n",
        "    for col in events_df.columns:\n",
        "        if 'f1' in col.lower() and 'height' in col.lower():\n",
        "            f1_height_col = col\n",
        "        if 'f2' in col.lower() and 'height' in col.lower():\n",
        "            f2_height_col = col\n",
        "\n",
        "    f1_reach_col = None\n",
        "    f2_reach_col = None\n",
        "    for col in events_df.columns:\n",
        "        if 'f1' in col.lower() and 'reach' in col.lower():\n",
        "            f1_reach_col = col\n",
        "        if 'f2' in col.lower() and 'reach' in col.lower():\n",
        "            f2_reach_col = col\n",
        "\n",
        "\n",
        "    if f1_age_col and f2_age_col:\n",
        "        f1_age_vals = pd.to_numeric(events_df[f1_age_col], errors='coerce').fillna(0)\n",
        "        f2_age_vals = pd.to_numeric(events_df[f2_age_col], errors='coerce').fillna(0)\n",
        "        events_df['age_diff'] = f1_age_vals - f2_age_vals\n",
        "    else:\n",
        "        events_df['age_diff'] = 0\n",
        "        print(\"Could not create age_diff\")\n",
        "\n",
        "    if f1_height_col and f2_height_col:\n",
        "        h1_vals = pd.to_numeric(events_df[f1_height_col], errors='coerce').fillna(0)\n",
        "        h2_vals = pd.to_numeric(events_df[f2_height_col], errors='coerce').fillna(0)\n",
        "        events_df['height_diff'] = h1_vals - h2_vals\n",
        "    else:\n",
        "        events_df['height_diff'] = 0\n",
        "        print(\"Could not create height_diff\")\n",
        "\n",
        "    if f1_reach_col and f2_reach_col:\n",
        "        r1_vals = pd.to_numeric(events_df[f1_reach_col], errors='coerce').fillna(0)\n",
        "        r2_vals = pd.to_numeric(events_df[f2_reach_col], errors='coerce').fillna(0)\n",
        "        events_df['reach_diff'] = r1_vals - r2_vals\n",
        "    else:\n",
        "        events_df['reach_diff'] = 0\n",
        "        print(\"Could not create reach_diff\")\n",
        "\n",
        "    for stat_name, col_pattern in [\n",
        "        ('slpm', 'slpm'),\n",
        "        ('sapm', 'sapm'),\n",
        "        ('str_acc', 'str_acc'),\n",
        "        ('str_def', 'str_def'),\n",
        "        ('td_avg', 'td_avg'),\n",
        "        ('td_acc', 'td_acc'),\n",
        "        ('td_def', 'td_def'),\n",
        "        ('sub_avg', 'sub_avg')\n",
        "    ]:\n",
        "        f1_col = None\n",
        "        f2_col = None\n",
        "        for col in events_df.columns:\n",
        "            if 'f1' in col.lower() and col_pattern in col.lower():\n",
        "                f1_col = col\n",
        "            if 'f2' in col.lower() and col_pattern in col.lower():\n",
        "                f2_col = col\n",
        "\n",
        "        if f1_col and f2_col:\n",
        "            f1_vals = pd.to_numeric(events_df[f1_col], errors='coerce').fillna(0)\n",
        "            f2_vals = pd.to_numeric(events_df[f2_col], errors='coerce').fillna(0)\n",
        "            events_df[f'{stat_name}_diff'] = f1_vals - f2_vals\n",
        "        else:\n",
        "            events_df[f'{stat_name}_diff'] = 0\n",
        "            print(f\"Could not create {stat_name}_diff\")\n",
        "\n",
        "    sub_patterns = ['sub_avg', 'sub_attempts', 'submission_avg']\n",
        "    for pattern in sub_patterns:\n",
        "        f1_col = f'f1_{pattern}'\n",
        "        f2_col = f'f2_{pattern}'\n",
        "        if f1_col in events_df.columns and f2_col in events_df.columns:\n",
        "            events_df['sub_avg_diff'] = events_df[f1_col] - events_df[f2_col]\n",
        "            break\n",
        "\n",
        "    if 'weight_class' not in events_df.columns:\n",
        "        for col in events_df.columns:\n",
        "            if 'weight' in col.lower():\n",
        "                events_df['weight_class'] = events_df[col]\n",
        "                break\n",
        "        if 'weight_class' not in events_df.columns:\n",
        "            events_df['weight_class'] = 'unknown'\n",
        "\n",
        "    f1_stance_col = None\n",
        "    f2_stance_col = None\n",
        "\n",
        "    for col in events_df.columns:\n",
        "        if 'f1' in col and 'stance' in col:\n",
        "            f1_stance_col = col\n",
        "        elif 'f2' in col and 'stance' in col:\n",
        "            f2_stance_col = col\n",
        "\n",
        "    if f1_stance_col and f2_stance_col:\n",
        "        events_df['stance_f1'] = events_df[f1_stance_col].astype(str).str.lower().str.strip()\n",
        "        events_df['stance_f2'] = events_df[f2_stance_col].astype(str).str.lower().str.strip()\n",
        "        events_df['stance_matchup'] = events_df['stance_f1'] + '_vs_' + events_df['stance_f2']\n",
        "    else:\n",
        "        events_df['stance_f1'] = 'unknown'\n",
        "        events_df['stance_f2'] = 'unknown'\n",
        "        events_df['stance_matchup'] = 'unknown_vs_unknown'\n",
        "\n",
        "\n",
        "    winner_col = None\n",
        "    for col in events_df.columns:\n",
        "        if 'winner' in col.lower() and 'odds' not in col.lower():\n",
        "            winner_col = col\n",
        "            break\n",
        "\n",
        "    f1_name_col = None\n",
        "    f2_name_col = None\n",
        "    for col in events_df.columns:\n",
        "        if ('f1' in col.lower() and 'name' in col.lower()) or col == 'fighter1' or col == 'fighter1_name':\n",
        "            f1_name_col = col\n",
        "        if ('f2' in col.lower() and 'name' in col.lower()) or col == 'fighter2' or col == 'fighter2_name':\n",
        "            f2_name_col = col\n",
        "\n",
        "    if winner_col and f1_name_col:\n",
        "        events_df['y_winner'] = (\n",
        "            events_df[winner_col].astype(str).str.lower().str.strip() ==\n",
        "            events_df[f1_name_col].astype(str).str.lower().str.strip()\n",
        "        ).astype(int)\n",
        "\n",
        "    elif 'result' in events_df.columns:\n",
        "\n",
        "        f1_id_col = None\n",
        "        f2_id_col = None\n",
        "\n",
        "        for col in events_df.columns:\n",
        "            if col == 'f1_id' or ('f1' in col.lower() and 'id' in col.lower()):\n",
        "                f1_id_col = col\n",
        "            if col == 'f2_id' or ('f2' in col.lower() and 'id' in col.lower()):\n",
        "                f2_id_col = col\n",
        "\n",
        "        if f1_id_col and f2_id_col:\n",
        "            result_vals = pd.to_numeric(events_df['result'], errors='coerce')\n",
        "            f1_ids = pd.to_numeric(events_df[f1_id_col], errors='coerce')\n",
        "            f2_ids = pd.to_numeric(events_df[f2_id_col], errors='coerce')\n",
        "\n",
        "            match_f1 = pd.Series(result_vals == f1_ids)\n",
        "            events_df['y_winner'] = match_f1.astype(int)\n",
        "\n",
        "            if events_df['y_winner'].sum() == 0:\n",
        "                print(\"Warning: No matches found between result and f1_id\")\n",
        "                print(\"Trying alternative: checking if result matches f2_id...\")\n",
        "                match_f2 = pd.Series(result_vals == f2_ids)\n",
        "                events_df['y_winner'] = match_f2.astype(int)\n",
        "                if events_df['y_winner'].sum() == len(events_df):\n",
        "                    events_df['y_winner'] = 0\n",
        "                    print(\"All results match f2_id - setting y_winner to 0 for all\")\n",
        "                else:\n",
        "                    events_df['y_winner'] = match_f1.astype(int)\n",
        "        else:\n",
        "            events_df['y_winner'] = 0\n",
        "            print(\"Warning: Could not determine y_winner - missing ID columns\")\n",
        "    else:\n",
        "        events_df['y_winner'] = 0\n",
        "        print(\"Warning: No winner/result column found, y_winner set to default\")\n",
        "\n",
        "    print(f\"\\nTarget distribution:\\n{events_df['y_winner'].value_counts()}\")\n",
        "\n",
        "    return events_df"
      ],
      "metadata": {
        "id": "ZMsweiImYUas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_and_merge_data(fighters_df, events_df, api_client=None):\n",
        "    \"\"\"\n",
        "    Complete data cleaning and merging pipeline.\n",
        "    \"\"\"\n",
        "    fighters_df = clean_fighters_df(fighters_df)\n",
        "\n",
        "    events_df, fighter_cols = clean_events_df(events_df)\n",
        "\n",
        "    if api_client:\n",
        "        events_df = api_client.enrich_fights_with_api_data(events_df)\n",
        "\n",
        "    events_df = merge_fighter_averages(events_df, fighters_df)\n",
        "\n",
        "    events_df = build_pre_fight_features(events_df)\n",
        "\n",
        "    return events_df, fighters_df"
      ],
      "metadata": {
        "id": "PQ3nf5vTZgAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_eda(events_df):\n",
        "    \"\"\"\n",
        "    Exploratory data analysis and sanity checks.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    key_features = [\n",
        "        'age_diff', 'height_diff', 'reach_diff', 'slpm_diff', 'sapm_diff',\n",
        "        'str_acc_diff', 'str_def_diff', 'td_avg_diff', 'td_acc_diff', 'td_def_diff'\n",
        "    ]\n",
        "\n",
        "    key_features = [f for f in key_features if f in events_df.columns]\n",
        "\n",
        "    print(\"\\nSummary Statistics of Key Features:\")\n",
        "    print(events_df[key_features].describe())\n",
        "\n",
        "    n_features = len(key_features)\n",
        "    n_cols = 3\n",
        "    n_rows = (n_features + n_cols - 1) // n_cols\n",
        "\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
        "    axes = axes.flatten() if n_features > 1 else [axes]\n",
        "\n",
        "    for idx, feature in enumerate(key_features):\n",
        "        if idx < len(axes):\n",
        "            axes[idx].hist(events_df[feature].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
        "            axes[idx].set_title(f'Distribution of {feature}')\n",
        "            axes[idx].set_xlabel(feature)\n",
        "            axes[idx].set_ylabel('Frequency')\n",
        "\n",
        "    for idx in range(len(key_features), len(axes)):\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('feature_distributions.png', dpi=150, bbox_inches='tight')\n",
        "    print(\"\\nSaved feature_distributions.png\")\n",
        "    plt.close()\n",
        "\n",
        "    corr_matrix = events_df[key_features].corr()\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
        "                square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
        "    plt.title('Correlation Matrix of Numeric Features')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('correlation_matrix.png', dpi=150, bbox_inches='tight')\n",
        "    print(\"Saved correlation_matrix.png\")\n",
        "    plt.close()\n",
        "\n",
        "    if 'weight_class' in events_df.columns:\n",
        "        print(\"\\nWin Rates by Weight Class:\")\n",
        "        weight_class_win_rates = events_df.groupby('weight_class')['y_winner'].agg(['mean', 'count'])\n",
        "        weight_class_win_rates.columns = ['win_rate', 'count']\n",
        "        print(weight_class_win_rates.sort_values('count', ascending=False))\n",
        "\n",
        "    if 'stance_matchup' in events_df.columns:\n",
        "        print(\"\\nWin Rates by Stance Matchup:\")\n",
        "        stance_win_rates = events_df.groupby('stance_matchup')['y_winner'].agg(['mean', 'count'])\n",
        "        stance_win_rates.columns = ['win_rate', 'count']\n",
        "        print(stance_win_rates.sort_values('count', ascending=False).head(10))\n",
        "\n",
        "    if 'reach_diff' in events_df.columns:\n",
        "        events_df['reach_advantage'] = pd.cut(\n",
        "            events_df['reach_diff'],\n",
        "            bins=[-np.inf, -5, 0, 5, np.inf],\n",
        "            labels=['Large Disadvantage', 'Small Disadvantage', 'Small Advantage', 'Large Advantage']\n",
        "        )\n",
        "        print(\"\\nWin Rates by Reach Advantage:\")\n",
        "        reach_win_rates = events_df.groupby('reach_advantage')['y_winner'].agg(['mean', 'count'])\n",
        "        reach_win_rates.columns = ['win_rate', 'count']\n",
        "        print(reach_win_rates)"
      ],
      "metadata": {
        "id": "iYsAj1dTZjGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_validation_split_data(X, y_winner):\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y_winner, test_size=0.2, stratify=y_winner, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
        "    print(f\"Validation set: {X_val.shape[0]} samples\")\n",
        "    print(f\"Train target distribution:\\n{y_train.value_counts()}\")\n",
        "    print(f\"Validation target distribution:\\n{y_val.value_counts()}\")\n",
        "\n",
        "    return X_train, X_val, y_train, y_val"
      ],
      "metadata": {
        "id": "eePp9jdYZw6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_preprocessing_pipeline(X_train):\n",
        "\n",
        "    numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    categorical_cols = X_train.select_dtypes(include=[object]).columns.tolist()\n",
        "\n",
        "    print(f\"\\nNumeric features ({len(numeric_cols)}): {numeric_cols}\")\n",
        "    print(f\"Categorical features ({len(categorical_cols)}): {categorical_cols}\")\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', StandardScaler(), numeric_cols),\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "\n",
        "    return preprocessor, numeric_cols, categorical_cols"
      ],
      "metadata": {
        "id": "NW6yaG1MZz0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_models(X_train, y_train, preprocessor):\n",
        "    \"\"\"\n",
        "    Train 5 models: Logistic Regression, Decision Tree, Random Forest,\n",
        "    Gradient Boosting, and XGBoost (with Optuna tuning).\n",
        "    Uses the shared preprocessor in all pipelines.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TRAINING MODELS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    models = {}\n",
        "\n",
        "    print(\"\\n[1/5] Training Logistic Regression...\")\n",
        "    log_reg_pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
        "    ])\n",
        "    log_reg_pipeline.fit(X_train, y_train)\n",
        "    models['log_reg'] = log_reg_pipeline\n",
        "\n",
        "    print(\"[2/5] Training Decision Tree...\")\n",
        "    dt_pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', DecisionTreeClassifier(random_state=42, max_depth=10))\n",
        "    ])\n",
        "    dt_pipeline.fit(X_train, y_train)\n",
        "    models['decision_tree'] = dt_pipeline\n",
        "\n",
        "    print(\"[3/5] Training Random Forest...\")\n",
        "    rf_pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10))\n",
        "    ])\n",
        "    rf_pipeline.fit(X_train, y_train)\n",
        "    models['random_forest'] = rf_pipeline\n",
        "\n",
        "    print(\"[4/5] Training Gradient Boosting...\")\n",
        "    gb_pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', GradientBoostingClassifier(n_estimators=100, random_state=42, max_depth=5))\n",
        "    ])\n",
        "    gb_pipeline.fit(X_train, y_train)\n",
        "    models['gradient_boosting'] = gb_pipeline\n",
        "\n",
        "    print(\"[5/5] Training XGBoost with Optuna tuning...\")\n",
        "    xgb_best_pipeline = tune_xgboost_with_optuna(X_train, y_train, preprocessor)\n",
        "    models['xgboost_optuna'] = xgb_best_pipeline\n",
        "\n",
        "    return models"
      ],
      "metadata": {
        "id": "l2fMeQt0Z13T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_xgboost_with_optuna(X_train, y_train, preprocessor):\n",
        "    \"\"\"\n",
        "    Tune XGBoost hyperparameters using Optuna.\n",
        "    \"\"\"\n",
        "    X_train_processed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=50),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "            'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
        "            'random_state': 42,\n",
        "            'eval_metric': 'logloss'\n",
        "        }\n",
        "\n",
        "        model = XGBClassifier(**params)\n",
        "\n",
        "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        f1_scores = []\n",
        "\n",
        "        for train_idx, val_idx in skf.split(X_train_processed, y_train):\n",
        "            X_train_fold = X_train_processed[train_idx]\n",
        "            X_val_fold = X_train_processed[val_idx]\n",
        "            y_train_fold = y_train.iloc[train_idx] if hasattr(y_train, 'iloc') else y_train[train_idx]\n",
        "            y_val_fold = y_train.iloc[val_idx] if hasattr(y_train, 'iloc') else y_train[val_idx]\n",
        "\n",
        "            model.fit(X_train_fold, y_train_fold)\n",
        "            y_pred = model.predict(X_val_fold)\n",
        "            f1_scores.append(float(f1_score(y_val_fold, y_pred)))\n",
        "\n",
        "        return float(np.mean(f1_scores))\n",
        "\n",
        "    print(\"  Running Optuna optimization (50 trials)...\")\n",
        "    study = optuna.create_study(direction='maximize', study_name='xgboost_optimization')\n",
        "    study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "    print(f\"  Best F1 score: {study.best_value:.4f}\")\n",
        "    print(f\"  Best parameters: {study.best_params}\")\n",
        "\n",
        "    best_params = study.best_params.copy()\n",
        "    best_params['random_state'] = 42\n",
        "    best_params['eval_metric'] = 'logloss'\n",
        "\n",
        "    best_xgb = XGBClassifier(**best_params)\n",
        "    best_xgb.fit(X_train_processed, y_train)\n",
        "\n",
        "    xgb_pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', best_xgb)\n",
        "    ])\n",
        "\n",
        "    return xgb_pipeline"
      ],
      "metadata": {
        "id": "-dWtgDElZ3xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_models(models, X_train, X_val, y_train, y_val):\n",
        "    \"\"\"\n",
        "    Evaluate all models on both train and validation sets.\n",
        "    Returns a DataFrame with metrics sorted by validation F1 score.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MODEL EVALUATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for model_name, pipeline in models.items():\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        y_train_pred = pipeline.predict(X_train)\n",
        "        train_acc = accuracy_score(y_train, y_train_pred)\n",
        "        train_prec = precision_score(y_train, y_train_pred, zero_division=0)\n",
        "        train_rec = recall_score(y_train, y_train_pred, zero_division=0)\n",
        "        train_f1 = f1_score(y_train, y_train_pred, zero_division=0)\n",
        "\n",
        "        y_val_pred = pipeline.predict(X_val)\n",
        "        val_acc = accuracy_score(y_val, y_val_pred)\n",
        "        val_prec = precision_score(y_val, y_val_pred, zero_division=0)\n",
        "        val_rec = recall_score(y_val, y_val_pred, zero_division=0)\n",
        "        val_f1 = f1_score(y_val, y_val_pred, zero_division=0)\n",
        "\n",
        "        print(f\"Train - Accuracy: {train_acc:.4f}, Precision: {train_prec:.4f}, \"\n",
        "              f\"Recall: {train_rec:.4f}, F1: {train_f1:.4f}\")\n",
        "        print(f\"Val   - Accuracy: {val_acc:.4f}, Precision: {val_prec:.4f}, \"\n",
        "              f\"Recall: {val_rec:.4f}, F1: {val_f1:.4f}\")\n",
        "\n",
        "        if train_acc > val_acc + 0.15:\n",
        "            print(\"  WARNING: High train but low val -> Overfitting detected\")\n",
        "        elif train_acc < 0.6 and val_acc < 0.6:\n",
        "            print(\"  WARNING: Low train and low val -> Underfitting or weak features\")\n",
        "        else:\n",
        "            print(\"  OK: Good generalization\")\n",
        "\n",
        "        cm = confusion_matrix(y_val, y_val_pred)\n",
        "        print(f\"\\nConfusion Matrix (Validation):\\n{cm}\")\n",
        "\n",
        "        results.append({\n",
        "            'model_name': model_name,\n",
        "            'train_accuracy': train_acc,\n",
        "            'train_f1': train_f1,\n",
        "            'val_accuracy': val_acc,\n",
        "            'val_precision': val_prec,\n",
        "            'val_recall': val_rec,\n",
        "            'val_f1': val_f1\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df = results_df.sort_values('val_f1', ascending=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MODEL COMPARISON SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MODEL DIAGNOSIS\")\n",
        "    print(\"=\"*60)\n",
        "    for _, row in results_df.iterrows():\n",
        "        model_name = row['model_name']\n",
        "        train_acc = row['train_accuracy']\n",
        "        val_acc = row['val_accuracy']\n",
        "        if train_acc > val_acc + 0.15:\n",
        "            print(f\"  {model_name}: Overfitting (train={train_acc:.3f}, val={val_acc:.3f})\")\n",
        "        elif train_acc < 0.6 and val_acc < 0.6:\n",
        "            print(f\"  {model_name}: Underfitting (train={train_acc:.3f}, val={val_acc:.3f})\")\n",
        "\n",
        "    return results_df"
      ],
      "metadata": {
        "id": "2rKFMS0wZ58k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_best_model(models, results_df):\n",
        "    \"\"\"\n",
        "    Select the best model based on validation F1 score.\n",
        "    \"\"\"\n",
        "    best_model_name = results_df.iloc[0]['model_name']\n",
        "    best_model = models[best_model_name]\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"SELECTED BEST MODEL: {best_model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Validation F1 Score: {results_df.iloc[0]['val_f1']:.4f}\")\n",
        "    print(f\"Validation Accuracy: {results_df.iloc[0]['val_accuracy']:.4f}\")\n",
        "\n",
        "    return best_model"
      ],
      "metadata": {
        "id": "lJy1GYJXZ_Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_external_test_set(best_model, fighters_df, test_path='ufc_fight_test - Sheet1.csv'):\n",
        "    \"\"\"\n",
        "    Evaluate the trained model on a completely separate external test dataset.\n",
        "    Uses the exact same preprocessing as training.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EXTERNAL TEST SET EVALUATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"\\nLoading external test dataset: {test_path}\")\n",
        "    try:\n",
        "        external_test_df = pd.read_csv(test_path)\n",
        "        first_col_name: str = str(external_test_df.columns[0])\n",
        "        is_numeric_col = first_col_name.isdigit()\n",
        "        has_expected_keywords = any(c in first_col_name.lower() for c in ['id', 'name', 'age', 'height'])\n",
        "        if is_numeric_col or not has_expected_keywords:\n",
        "            print(\"No header row detected, using training CSV column structure...\")\n",
        "            train_df_sample = pd.read_csv('ufc_fight_train - ufc_event_fight_stats.csv', nrows=0)\n",
        "            column_names = train_df_sample.columns.tolist()\n",
        "            external_test_df = pd.read_csv(test_path, header=None, names=column_names)\n",
        "        print(f\"Loaded external test set: {external_test_df.shape}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Warning: External test file {test_path} not found. Skipping external evaluation.\")\n",
        "        return None\n",
        "\n",
        "    print(\"\\nApplying same preprocessing pipeline...\")\n",
        "\n",
        "    external_test_df, _ = clean_events_df(external_test_df)\n",
        "\n",
        "    external_test_df = merge_fighter_averages(external_test_df, fighters_df)\n",
        "\n",
        "    external_test_df = build_pre_fight_features(external_test_df)\n",
        "\n",
        "    print(f\"After preprocessing, shape: {external_test_df.shape}\")\n",
        "\n",
        "    print(\"Creating y_winner target from result column...\")\n",
        "    print(f\"Available columns after cleaning: {[c for c in external_test_df.columns if 'result' in c.lower() or 'winner' in c.lower()]}\")\n",
        "    result_col = None\n",
        "    for col in external_test_df.columns:\n",
        "        if col.lower() == 'result':\n",
        "            result_col = col\n",
        "            break\n",
        "\n",
        "    if result_col:\n",
        "        f1_id_col = None\n",
        "        f2_id_col = None\n",
        "        for col in external_test_df.columns:\n",
        "            if col == 'f1_id' or ('f1' in col.lower() and 'id' in col.lower()):\n",
        "                f1_id_col = col\n",
        "            if col == 'f2_id' or ('f2' in col.lower() and 'id' in col.lower()):\n",
        "                f2_id_col = col\n",
        "\n",
        "        if f1_id_col and f2_id_col:\n",
        "            result_vals = pd.to_numeric(external_test_df[result_col], errors='coerce')\n",
        "            f1_ids = pd.to_numeric(external_test_df[f1_id_col], errors='coerce')\n",
        "            f2_ids = pd.to_numeric(external_test_df[f2_id_col], errors='coerce')\n",
        "\n",
        "            match_f1 = pd.Series(result_vals == f1_ids)\n",
        "            external_test_df['y_winner'] = match_f1.astype(int)\n",
        "\n",
        "            if external_test_df['y_winner'].sum() == 0:\n",
        "                print(\"Warning: No matches found between result and f1_id, trying f2_id...\")\n",
        "                match_f2 = pd.Series(result_vals == f2_ids)\n",
        "                external_test_df['y_winner'] = match_f2.astype(int)\n",
        "                if external_test_df['y_winner'].sum() == len(external_test_df):\n",
        "                    external_test_df['y_winner'] = 0\n",
        "                else:\n",
        "                    external_test_df['y_winner'] = match_f1.astype(int)\n",
        "        else:\n",
        "            print(\"Warning: Could not find ID columns to create y_winner\")\n",
        "            external_test_df['y_winner'] = 0\n",
        "    else:\n",
        "        print(\"Warning: No 'result' column found. Cannot create y_winner.\")\n",
        "        return None\n",
        "\n",
        "    external_test_df = external_test_df.dropna(subset=['y_winner'])\n",
        "\n",
        "\n",
        "    pre_fight_features = [\n",
        "        'age_diff', 'height_diff', 'reach_diff', 'slpm_diff', 'sapm_diff',\n",
        "        'str_acc_diff', 'str_def_diff', 'td_avg_diff', 'td_acc_diff', 'td_def_diff',\n",
        "        'sub_avg_diff', 'weight_class', 'stance_f1', 'stance_f2', 'stance_matchup'\n",
        "    ]\n",
        "\n",
        "    available_features = [f for f in pre_fight_features if f in external_test_df.columns]\n",
        "\n",
        "    diff_features = [col for col in external_test_df.columns if '_diff' in col]\n",
        "    available_features = list(set(available_features + diff_features))\n",
        "\n",
        "    X_ext = external_test_df[available_features].copy()\n",
        "    y_ext = external_test_df['y_winner'].copy()\n",
        "\n",
        "    print(f\"\\nExternal test set ready:\")\n",
        "    print(f\"  Features: {X_ext.shape[1]}\")\n",
        "    print(f\"  Samples: {X_ext.shape[0]}\")\n",
        "    print(f\"  Target distribution: {y_ext.value_counts().to_dict()}\")\n",
        "\n",
        "    if len(X_ext) == 0:\n",
        "        print(\"Error: No samples in external test set after preprocessing\")\n",
        "        return None\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MAKING PREDICTIONS ON EXTERNAL TEST SET\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"\\nMaking predictions on {len(X_ext)} samples...\")\n",
        "    print(f\"Feature columns in X_ext: {list(X_ext.columns)[:10]}...\")\n",
        "\n",
        "    y_pred_ext = best_model.predict(X_ext)\n",
        "    y_proba_ext = best_model.predict_proba(X_ext)\n",
        "\n",
        "    print(f\"\\nPrediction distribution: {pd.Series(y_pred_ext).value_counts().to_dict()}\")\n",
        "    print(f\"Actual distribution: {y_ext.value_counts().to_dict()}\")\n",
        "\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EXTERNAL TEST SET METRICS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    ext_acc = accuracy_score(y_ext, y_pred_ext)\n",
        "    ext_prec = precision_score(y_ext, y_pred_ext, zero_division=0)\n",
        "    ext_rec = recall_score(y_ext, y_pred_ext, zero_division=0)\n",
        "    ext_f1 = f1_score(y_ext, y_pred_ext, zero_division=0)\n",
        "\n",
        "    print(f\"\\nExternal Test Accuracy:  {ext_acc:.4f} ({ext_acc*100:.2f}%)\")\n",
        "    print(f\"External Test Precision: {ext_prec:.4f} ({ext_prec*100:.2f}%)\")\n",
        "    print(f\"External Test Recall:    {ext_rec:.4f} ({ext_rec*100:.2f}%)\")\n",
        "    print(f\"External Test F1 Score:  {ext_f1:.4f} ({ext_f1*100:.2f}%)\")\n",
        "\n",
        "    cm_ext = confusion_matrix(y_ext, y_pred_ext)\n",
        "    print(f\"\\nConfusion Matrix (External Test):\")\n",
        "    print(cm_ext)\n",
        "\n",
        "    print(f\"\\nClassification Report (External Test):\")\n",
        "    print(classification_report(y_ext, y_pred_ext, target_names=['Fighter2 Wins', 'Fighter1 Wins']))\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PREDICTION VS ACTUAL RESULTS TABLE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    f1_name_col = None\n",
        "    f2_name_col = None\n",
        "    for col in external_test_df.columns:\n",
        "        if ('f1' in col.lower() and 'name' in col.lower()) or col == 'fighter1' or col == 'fighter1_name':\n",
        "            f1_name_col = col\n",
        "        if ('f2' in col.lower() and 'name' in col.lower()) or col == 'fighter2' or col == 'fighter2_name':\n",
        "            f2_name_col = col\n",
        "\n",
        "    if f1_name_col is None or f2_name_col is None:\n",
        "        print(\"Warning: Could not find fighter name columns for results table\")\n",
        "        f1_name_col = 'f1_name' if 'f1_name' in external_test_df.columns else external_test_df.columns[0]\n",
        "        f2_name_col = 'f2_name' if 'f2_name' in external_test_df.columns else external_test_df.columns[1]\n",
        "\n",
        "    results_table = []\n",
        "    for idx in range(len(external_test_df)):\n",
        "        f1_name = str(external_test_df.iloc[idx][f1_name_col]) if f1_name_col in external_test_df.columns else f\"Fighter1_{idx}\"\n",
        "        f2_name = str(external_test_df.iloc[idx][f2_name_col]) if f2_name_col in external_test_df.columns else f\"Fighter2_{idx}\"\n",
        "\n",
        "        actual_winner = f1_name if y_ext.iloc[idx] == 1 else f2_name\n",
        "        predicted_winner = f1_name if y_pred_ext[idx] == 1 else f2_name\n",
        "\n",
        "        proba = y_proba_ext[idx]\n",
        "        p_f1_win = proba[1] if len(proba) > 1 else proba[0]\n",
        "        p_f2_win = proba[0] if len(proba) > 1 else 1 - p_f1_win\n",
        "\n",
        "        results_table.append({\n",
        "            'fighter1': f1_name,\n",
        "            'fighter2': f2_name,\n",
        "            'actual_winner': actual_winner,\n",
        "            'predicted_winner': predicted_winner,\n",
        "            'predicted_prob_f1_win': p_f1_win,\n",
        "            'predicted_prob_f2_win': p_f2_win,\n",
        "            'correct': 1 if actual_winner == predicted_winner else 0\n",
        "        })\n",
        "\n",
        "    results_table_df = pd.DataFrame(results_table)\n",
        "\n",
        "    print(f\"\\nTotal fights: {len(results_table_df)}\")\n",
        "    print(f\"Correct predictions: {results_table_df['correct'].sum()}\")\n",
        "    print(f\"Accuracy: {results_table_df['correct'].mean():.2%}\")\n",
        "\n",
        "    print(f\"\\nFull Results Table:\")\n",
        "    print(results_table_df.to_string(index=False))\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PERFORMANCE COMPARISON SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"\\nExternal Test F1 Score: {ext_f1:.4f} ({ext_f1*100:.2f}%)\")\n",
        "    print(\"\\nNote: Compare this with:\")\n",
        "    print(\"  - Training F1 Score (from model training output)\")\n",
        "    print(\"  - Validation F1 Score (from model evaluation output)\")\n",
        "\n",
        "    if ext_f1 >= 0.70:\n",
        "        print(\"OK: Model generalized well to external test set\")\n",
        "        print(\"  The model maintains strong performance on unseen data.\")\n",
        "    elif ext_f1 >= 0.60:\n",
        "        print(\"WARNING: Model performance dropped moderately on external test set\")\n",
        "        print(\"  Some performance degradation, but still reasonable.\")\n",
        "    else:\n",
        "        print(\"WARNING: Model performance dropped significantly on external test set\")\n",
        "        print(\"  May indicate overfitting or distribution shift between train/test data.\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': ext_acc,\n",
        "        'precision': ext_prec,\n",
        "        'recall': ext_rec,\n",
        "        'f1': ext_f1,\n",
        "        'results_table': results_table_df\n",
        "    }"
      ],
      "metadata": {
        "id": "JCz-AbcVaAwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_matchup_row(fighter1_name, fighter2_name, weight_class, fighters_df):\n",
        "    \"\"\"\n",
        "    Build a pre-fight feature row for a specific matchup.\n",
        "\n",
        "    Args:\n",
        "        fighter1_name: Name of first fighter\n",
        "        fighter2_name: Name of second fighter\n",
        "        weight_class: Weight class of the fight\n",
        "        fighters_df: DataFrame with fighter averages\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with single row of pre-fight features\n",
        "    \"\"\"\n",
        "    fighter1_name = str(fighter1_name).lower().strip()\n",
        "    fighter2_name = str(fighter2_name).lower().strip()\n",
        "\n",
        "    fighters_name_col = None\n",
        "    for col in fighters_df.columns:\n",
        "        if 'name' in col.lower():\n",
        "            fighters_name_col = col\n",
        "            break\n",
        "\n",
        "    if fighters_name_col is None:\n",
        "        fighters_name_col = fighters_df.columns[0]\n",
        "\n",
        "    f1_row = None\n",
        "    f2_row = None\n",
        "\n",
        "    f1_search_terms = [fighter1_name]\n",
        "    f2_search_terms = [fighter2_name]\n",
        "\n",
        "    f1_parts = fighter1_name.split()\n",
        "    f2_parts = fighter2_name.split()\n",
        "    if len(f1_parts) > 1:\n",
        "        f1_search_terms.extend([f1_parts[-1], ' '.join(f1_parts[-2:])])\n",
        "    if len(f2_parts) > 1:\n",
        "        f2_search_terms.extend([f2_parts[-1], ' '.join(f2_parts[-2:])])  #\n",
        "    for idx, row in fighters_df.iterrows():\n",
        "        name_val = str(row[fighters_name_col]).lower().strip()\n",
        "\n",
        "        if f1_row is None:\n",
        "            for term in f1_search_terms:\n",
        "                if term in name_val or name_val in term:\n",
        "                    f1_row = row\n",
        "                    break\n",
        "\n",
        "        if f2_row is None:\n",
        "            for term in f2_search_terms:\n",
        "                if term in name_val or name_val in term:\n",
        "                    f2_row = row\n",
        "                    break\n",
        "\n",
        "    if f1_row is None:\n",
        "        # Print available fighters for debugging\n",
        "        print(f\"\\nAvailable fighters (first 20):\")\n",
        "        for idx, row in fighters_df.head(20).iterrows():\n",
        "            print(f\"  - {row[fighters_name_col]}\")\n",
        "        raise ValueError(f\"Fighter 1 '{fighter1_name}' not found in fighters_df. Try checking the exact name in the CSV.\")\n",
        "    if f2_row is None:\n",
        "        # Print available fighters for debugging\n",
        "        print(f\"\\nAvailable fighters (first 20):\")\n",
        "        for idx, row in fighters_df.head(20).iterrows():\n",
        "            print(f\"  - {row[fighters_name_col]}\")\n",
        "        raise ValueError(f\"Fighter 2 '{fighter2_name}' not found in fighters_df. Try checking the exact name in the CSV.\")\n",
        "\n",
        "    def get_val(row, key_patterns, default=0):\n",
        "        for pattern in key_patterns:\n",
        "            for col in row.index:\n",
        "                if pattern.lower() in col.lower():\n",
        "                    val = row[col]\n",
        "                    if pd.notna(val) and val != '':\n",
        "                        try:\n",
        "                            return float(val)\n",
        "                        except (ValueError, TypeError):\n",
        "                            return default\n",
        "        return default\n",
        "\n",
        "    # Build difference features\n",
        "    matchup_data = {}\n",
        "\n",
        "    # Age difference\n",
        "    f1_age = get_val(f1_row, ['age'], 0)\n",
        "    f2_age = get_val(f2_row, ['age'], 0)\n",
        "    matchup_data['age_diff'] = f1_age - f2_age\n",
        "\n",
        "    # Height difference\n",
        "    f1_height = get_val(f1_row, ['height', 'ht'], 0)\n",
        "    f2_height = get_val(f2_row, ['height', 'ht'], 0)\n",
        "    matchup_data['height_diff'] = f1_height - f2_height\n",
        "\n",
        "    # Reach difference\n",
        "    f1_reach = get_val(f1_row, ['reach'], 0)\n",
        "    f2_reach = get_val(f2_row, ['reach'], 0)\n",
        "    matchup_data['reach_diff'] = f1_reach - f2_reach\n",
        "\n",
        "    # Striking stats\n",
        "    f1_slpm = get_val(f1_row, ['slpm', 'strikes_landed_per_min'], 0)\n",
        "    f2_slpm = get_val(f2_row, ['slpm', 'strikes_landed_per_min'], 0)\n",
        "    matchup_data['slpm_diff'] = f1_slpm - f2_slpm\n",
        "\n",
        "    f1_sapm = get_val(f1_row, ['sapm', 'strikes_absorbed_per_min'], 0)\n",
        "    f2_sapm = get_val(f2_row, ['sapm', 'strikes_absorbed_per_min'], 0)\n",
        "    matchup_data['sapm_diff'] = f1_sapm - f2_sapm\n",
        "\n",
        "    f1_str_acc = get_val(f1_row, ['str_acc', 'striking_accuracy'], 0)\n",
        "    f2_str_acc = get_val(f2_row, ['str_acc', 'striking_accuracy'], 0)\n",
        "    matchup_data['str_acc_diff'] = f1_str_acc - f2_str_acc\n",
        "\n",
        "    f1_str_def = get_val(f1_row, ['str_def', 'striking_defense'], 0)\n",
        "    f2_str_def = get_val(f2_row, ['str_def', 'striking_defense'], 0)\n",
        "    matchup_data['str_def_diff'] = f1_str_def - f2_str_def\n",
        "\n",
        "    # Grappling stats\n",
        "    f1_td_avg = get_val(f1_row, ['td_avg', 'takedown_avg'], 0)\n",
        "    f2_td_avg = get_val(f2_row, ['td_avg', 'takedown_avg'], 0)\n",
        "    matchup_data['td_avg_diff'] = f1_td_avg - f2_td_avg\n",
        "\n",
        "    f1_td_acc = get_val(f1_row, ['td_acc', 'takedown_accuracy'], 0)\n",
        "    f2_td_acc = get_val(f2_row, ['td_acc', 'takedown_accuracy'], 0)\n",
        "    matchup_data['td_acc_diff'] = f1_td_acc - f2_td_acc\n",
        "\n",
        "    f1_td_def = get_val(f1_row, ['td_def', 'takedown_defense'], 0)\n",
        "    f2_td_def = get_val(f2_row, ['td_def', 'takedown_defense'], 0)\n",
        "    matchup_data['td_def_diff'] = f1_td_def - f2_td_def\n",
        "\n",
        "    # Submission stats\n",
        "    f1_sub_avg = get_val(f1_row, ['sub_avg', 'submission_avg'], 0)\n",
        "    f2_sub_avg = get_val(f2_row, ['sub_avg', 'submission_avg'], 0)\n",
        "    matchup_data['sub_avg_diff'] = f1_sub_avg - f2_sub_avg\n",
        "\n",
        "    # Categorical features\n",
        "    matchup_data['weight_class'] = str(weight_class).lower().strip()\n",
        "\n",
        "    f1_stance = 'unknown'\n",
        "    f2_stance = 'unknown'\n",
        "    for col in f1_row.index:\n",
        "        if 'stance' in col.lower():\n",
        "            val = f1_row[col]\n",
        "            if pd.notna(val) and val != '':\n",
        "                f1_stance = str(val).lower().strip()\n",
        "                break\n",
        "    for col in f2_row.index:\n",
        "        if 'stance' in col.lower():\n",
        "            val = f2_row[col]\n",
        "            if pd.notna(val) and val != '':\n",
        "                f2_stance = str(val).lower().strip()\n",
        "                break\n",
        "\n",
        "    matchup_data['stance_f1'] = f1_stance\n",
        "    matchup_data['stance_f2'] = f2_stance\n",
        "    matchup_data['stance_matchup'] = f1_stance + '_vs_' + f2_stance\n",
        "\n",
        "    matchup_df = pd.DataFrame([matchup_data])\n",
        "\n",
        "    return matchup_df"
      ],
      "metadata": {
        "id": "4BbBdGvjaNfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_specific_fights(best_model, fighters_df):\n",
        "    \"\"\"\n",
        "    Predict outcomes for the two specific upcoming fights.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PREDICTING SPECIFIC FIGHTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    matchups = [\n",
        "        {\n",
        "            'fighter1': 'Jack Della Maddalena',\n",
        "            'fighter2': 'Islam Makhachev',\n",
        "            'weight_class': 'Welterweight',\n",
        "            'event_type': 'Main Event'\n",
        "        },\n",
        "        {\n",
        "            'fighter1': 'Valentina Shevchenko',\n",
        "            'fighter2': 'Zhang Weili',  # Name as it appears in CSV (last name first)\n",
        "            'weight_class': \"Women Flyweight\",\n",
        "            'event_type': 'Co-main'\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    for matchup in matchups:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"{matchup['event_type']}: {matchup['fighter1']} vs {matchup['fighter2']}\")\n",
        "        print(f\"Weight Class: {matchup['weight_class']}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        try:\n",
        "            matchup_df = build_matchup_row(\n",
        "                matchup['fighter1'],\n",
        "                matchup['fighter2'],\n",
        "                matchup['weight_class'],\n",
        "                fighters_df\n",
        "            )\n",
        "\n",
        "\n",
        "            print(\"\\nDetailed Feature Breakdown:\")\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "            feature_list = [\n",
        "                ('reach_diff', 'Reach Difference'),\n",
        "                ('height_diff', 'Height Difference'),\n",
        "                ('age_diff', 'Age Difference'),\n",
        "                ('slpm_diff', 'Strikes Landed/Min Difference'),\n",
        "                ('str_acc_diff', 'Striking Accuracy Difference'),\n",
        "                ('td_avg_diff', 'Takedown Average Difference'),\n",
        "                ('td_def_diff', 'Takedown Defense Difference'),\n",
        "            ]\n",
        "\n",
        "            for feat_key, feat_name in feature_list:\n",
        "                if feat_key in matchup_df.columns:\n",
        "                    val = matchup_df[feat_key].iloc[0]\n",
        "                    print(f\"  {feat_name:35s}: {val:8.2f}\")\n",
        "                else:\n",
        "                    print(f\"  {feat_name:35s}: Not available\")\n",
        "\n",
        "            if 'stance_matchup' in matchup_df.columns:\n",
        "                print(f\"\\n  Stance Matchup: {matchup_df['stance_matchup'].iloc[0]}\")\n",
        "\n",
        "            proba = best_model.predict_proba(matchup_df)[0]\n",
        "            prediction = best_model.predict(matchup_df)[0]\n",
        "\n",
        "            p_f1_win = proba[1] if len(proba) > 1 else proba[0]\n",
        "            p_f2_win = proba[0] if len(proba) > 1 else 1 - p_f1_win\n",
        "\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(\"PREDICTION RESULTS:\")\n",
        "            print(f\"{'='*60}\")\n",
        "            print(f\"{matchup['fighter1']:30s}: {p_f1_win:.2%} win probability\")\n",
        "            print(f\"{matchup['fighter2']:30s}: {p_f2_win:.2%} win probability\")\n",
        "            print(f\"\\nPredicted Winner: {matchup['fighter1'] if prediction == 1 else matchup['fighter2']}\")\n",
        "\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(\"MODEL INTERPRETATION:\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            # Determine favored fighter\n",
        "            favored_fighter = matchup['fighter1'] if p_f1_win > 0.5 else matchup['fighter2']\n",
        "            favored_prob = max(p_f1_win, p_f2_win)\n",
        "\n",
        "            print(f\"\\nModel favors {favored_fighter} with {favored_prob:.1%} win probability.\")\n",
        "\n",
        "            # Analyze key advantages\n",
        "            advantages = []\n",
        "\n",
        "            if 'reach_diff' in matchup_df.columns:\n",
        "                reach_diff = matchup_df['reach_diff'].iloc[0]\n",
        "                if abs(reach_diff) > 2:\n",
        "                    if reach_diff > 0:\n",
        "                        advantages.append(f\"{matchup['fighter1']} has {reach_diff:.1f}cm reach advantage\")\n",
        "                    else:\n",
        "                        advantages.append(f\"{matchup['fighter2']} has {abs(reach_diff):.1f}cm reach advantage\")\n",
        "\n",
        "            if 'height_diff' in matchup_df.columns:\n",
        "                height_diff = matchup_df['height_diff'].iloc[0]\n",
        "                if abs(height_diff) > 2:\n",
        "                    if height_diff > 0:\n",
        "                        advantages.append(f\"{matchup['fighter1']} has {height_diff:.1f}cm height advantage\")\n",
        "                    else:\n",
        "                        advantages.append(f\"{matchup['fighter2']} has {abs(height_diff):.1f}cm height advantage\")\n",
        "\n",
        "            if 'age_diff' in matchup_df.columns:\n",
        "                age_diff = matchup_df['age_diff'].iloc[0]\n",
        "                if abs(age_diff) > 2:\n",
        "                    if age_diff < 0:\n",
        "                        advantages.append(f\"{matchup['fighter1']} is {abs(age_diff):.0f} years younger\")\n",
        "                    else:\n",
        "                        advantages.append(f\"{matchup['fighter2']} is {age_diff:.0f} years younger\")\n",
        "\n",
        "            if 'td_avg_diff' in matchup_df.columns:\n",
        "                td_diff = matchup_df['td_avg_diff'].iloc[0]\n",
        "                if abs(td_diff) > 0.5:\n",
        "                    if td_diff > 0:\n",
        "                        advantages.append(f\"{matchup['fighter1']} has superior takedown average (+{td_diff:.2f} per 15min)\")\n",
        "                    else:\n",
        "                        advantages.append(f\"{matchup['fighter2']} has superior takedown average (+{abs(td_diff):.2f} per 15min)\")\n",
        "\n",
        "            if 'td_def_diff' in matchup_df.columns:\n",
        "                td_def_diff = matchup_df['td_def_diff'].iloc[0]\n",
        "                if abs(td_def_diff) > 5:\n",
        "                    if td_def_diff > 0:\n",
        "                        advantages.append(f\"{matchup['fighter1']} has better takedown defense (+{td_def_diff:.1f}%)\")\n",
        "                    else:\n",
        "                        advantages.append(f\"{matchup['fighter2']} has better takedown defense (+{abs(td_def_diff):.1f}%)\")\n",
        "\n",
        "            if 'str_acc_diff' in matchup_df.columns:\n",
        "                str_acc_diff = matchup_df['str_acc_diff'].iloc[0]\n",
        "                if abs(str_acc_diff) > 3:\n",
        "                    if str_acc_diff > 0:\n",
        "                        advantages.append(f\"{matchup['fighter1']} has higher striking accuracy (+{str_acc_diff:.1f}%)\")\n",
        "                    else:\n",
        "                        advantages.append(f\"{matchup['fighter2']} has higher striking accuracy (+{abs(str_acc_diff):.1f}%)\")\n",
        "\n",
        "            if 'slpm_diff' in matchup_df.columns:\n",
        "                slpm_diff = matchup_df['slpm_diff'].iloc[0]\n",
        "                if abs(slpm_diff) > 0.5:\n",
        "                    if slpm_diff > 0:\n",
        "                        advantages.append(f\"{matchup['fighter1']} lands more strikes per minute (+{slpm_diff:.2f})\")\n",
        "                    else:\n",
        "                        advantages.append(f\"{matchup['fighter2']} lands more strikes per minute (+{abs(slpm_diff):.2f})\")\n",
        "\n",
        "            if advantages:\n",
        "                print(\"\\nKey advantages identified by the model:\")\n",
        "                for i, advantage in enumerate(advantages, 1):\n",
        "                    print(f\"  {i}. {advantage}\")\n",
        "            else:\n",
        "                print(\"\\nFighters appear relatively balanced across key metrics.\")\n",
        "\n",
        "            predictions.append({\n",
        "                'fighter1': matchup['fighter1'],\n",
        "                'fighter2': matchup['fighter2'],\n",
        "                'weight_class': matchup['weight_class'],\n",
        "                'p_f1_win': p_f1_win,\n",
        "                'p_f2_win': p_f2_win,\n",
        "                'predicted_winner': matchup['fighter1'] if prediction == 1 else matchup['fighter2']\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError predicting {matchup['fighter1']} vs {matchup['fighter2']}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    predictions_df = pd.DataFrame(predictions)\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"PREDICTIONS SUMMARY\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(predictions_df.to_string(index=False))\n",
        "\n",
        "    return predictions_df"
      ],
      "metadata": {
        "id": "Wsg_UPT3aZBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*60)\n",
        "    print(\"UFC FIGHT PREDICTION PIPELINE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    fighters_df, events_df = load_data(events_path='ufc_fight_train.csv')\n",
        "\n",
        "\n",
        "    events_df, fighters_df = clean_and_merge_data(fighters_df, events_df, api_client=None)\n",
        "\n",
        "    pre_fight_features = [\n",
        "        'age_diff', 'height_diff', 'reach_diff', 'slpm_diff', 'sapm_diff',\n",
        "        'str_acc_diff', 'str_def_diff', 'td_avg_diff', 'td_acc_diff', 'td_def_diff',\n",
        "        'sub_avg_diff', 'weight_class', 'stance_f1', 'stance_f2', 'stance_matchup'\n",
        "    ]\n",
        "\n",
        "    # Filter to features that exist\n",
        "    available_features = [f for f in events_df.columns if f in pre_fight_features]\n",
        "\n",
        "    # Also include any other difference features\n",
        "    diff_features = [col for col in events_df.columns if '_diff' in col]\n",
        "    available_features = list(set(available_features + diff_features))\n",
        "\n",
        "    # Ensure we have the target\n",
        "    if 'y_winner' not in events_df.columns:\n",
        "        print(\"Warning: y_winner not found. Creating default target...\")\n",
        "        events_df['y_winner'] = 0\n",
        "\n",
        "    # Remove rows with missing target\n",
        "    events_df = events_df.dropna(subset=['y_winner'])\n",
        "\n",
        "    X = events_df[available_features].copy()\n",
        "    y_winner = events_df['y_winner'].copy()\n",
        "\n",
        "    print(f\"\\nFinal modeling dataset:\")\n",
        "    print(f\"  Features: {X.shape[1]}\")\n",
        "    print(f\"  Samples: {X.shape[0]}\")\n",
        "    print(f\"  Target distribution: {y_winner.value_counts().to_dict()}\")\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    perform_eda(events_df)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_validation_split_data(X, y_winner)\n",
        "\n",
        "    preprocessor, numeric_cols, categorical_cols = build_preprocessing_pipeline(X_train)\n",
        "\n",
        "    models = train_models(X_train, y_train, preprocessor)\n",
        "\n",
        "    results_df = evaluate_models(models, X_train, X_val, y_train, y_val)\n",
        "\n",
        "    best_model = select_best_model(models, results_df)\n",
        "\n",
        "    ext_results = evaluate_external_test_set(best_model, fighters_df)\n",
        "\n",
        "    if ext_results:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"FINAL PERFORMANCE COMPARISON\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        best_model_name = results_df.iloc[0]['model_name']\n",
        "        best_model_row = results_df[results_df['model_name'] == best_model_name]\n",
        "        if len(best_model_row) > 0:\n",
        "            best_model_row = best_model_row.iloc[0]\n",
        "        else:\n",
        "            best_model_row = results_df.iloc[0]\n",
        "\n",
        "        train_f1_best = best_model_row['train_f1'] if 'train_f1' in best_model_row else None\n",
        "        if train_f1_best is None:\n",
        "            y_train_pred_best = best_model.predict(X_train)\n",
        "            train_f1_best = f1_score(y_train, y_train_pred_best, zero_division=0)\n",
        "\n",
        "        val_f1 = results_df.iloc[0]['val_f1']\n",
        "        ext_f1 = ext_results['f1']\n",
        "\n",
        "        print(f\"\\n{'Metric':<25} {'F1 Score':<15} {'Percentage':<15}\")\n",
        "        print(\"-\" * 55)\n",
        "        print(f\"{'Training F1':<25} {train_f1_best:<15.4f} {train_f1_best*100:<15.2f}%\")\n",
        "        print(f\"{'Validation F1':<25} {val_f1:<15.4f} {val_f1*100:<15.2f}%\")\n",
        "        print(f\"{'External Test F1':<25} {ext_f1:<15.4f} {ext_f1*100:<15.2f}%\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"GENERALIZATION ASSESSMENT\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        f1_diff = val_f1 - ext_f1\n",
        "        if abs(f1_diff) < 0.02:\n",
        "            print(\"OK: Model generalized very well\")\n",
        "            print(f\"  External test F1 ({ext_f1:.4f}) is very close to validation F1 ({val_f1:.4f})\")\n",
        "            print(f\"  Difference: {f1_diff:.4f}\")\n",
        "        elif f1_diff > 0.05:\n",
        "            print(\"WARNING: Model performance dropped on external test set\")\n",
        "            print(f\"  External test F1 ({ext_f1:.4f}) is lower than validation F1 ({val_f1:.4f})\")\n",
        "            print(f\"  Drop: {f1_diff:.4f} ({f1_diff*100:.2f} percentage points)\")\n",
        "            print(\"  Possible causes: distribution shift, different data quality, or overfitting\")\n",
        "        elif f1_diff < -0.02:\n",
        "            print(\"OK: Model improved unexpectedly on external test set\")\n",
        "            print(f\"  External test F1 ({ext_f1:.4f}) is higher than validation F1 ({val_f1:.4f})\")\n",
        "            print(f\"  Improvement: {abs(f1_diff):.4f} ({abs(f1_diff)*100:.2f} percentage points)\")\n",
        "        else:\n",
        "            print(\"OK: Model generalized well\")\n",
        "            print(f\"  External test F1 ({ext_f1:.4f}) is close to validation F1 ({val_f1:.4f})\")\n",
        "            print(f\"  Difference: {f1_diff:.4f}\")\n",
        "\n",
        "    predictions_df = predict_specific_fights(best_model, fighters_df)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PIPELINE COMPLETE\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nAll predictions have been generated and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6abffae2c1bf4f8f93996f0ebbc4de0e",
            "f7359bee6a9045ecaddb3d1adc362f32",
            "1aac54293d5f460ca8c343b6060df665",
            "d0eff80aca9443b8a12002f0e00ff3ac",
            "04fc97ced4a14512832002a20d6fe19f",
            "d850d41ae11e49ac82869437dae2d6e0",
            "769434084e5e4c92951888e7d1683797",
            "0147b56dadac4b4da6899ed30d1dfe2e",
            "c27eff96be7148b48b4922c190283930",
            "71dc03a08b854cf390f1d0d7a4d006e0",
            "7dd61ff97dd84caf8a533f8e1528570f"
          ]
        },
        "id": "nYklg5jmaoAq",
        "outputId": "722425cb-cf16-41cf-976a-d2cc782a483c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "UFC FIGHT PREDICTION PIPELINE\n",
            "============================================================\n",
            "Loading data...\n",
            "Loaded fighters_df: (4262, 42)\n",
            "Loaded events_df: (5898, 58)\n",
            "\n",
            "============================================================\n",
            "CLEANING FIGHTERS_DF\n",
            "============================================================\n",
            "\n",
            "Shape: (4262, 42)\n",
            "\n",
            "Dtypes:\n",
            "fighter_id                int64\n",
            "fighter_name             object\n",
            "fighter_dob              object\n",
            "fighter_height_cm       float64\n",
            "fighter_weight_lbs      float64\n",
            "fighter_reach_cm        float64\n",
            "fighter_stance           object\n",
            "fighter_wins              int64\n",
            "fighter_losses            int64\n",
            "fighter_draws             int64\n",
            "fighter_slpm            float64\n",
            "fighter_str_acc_%       float64\n",
            "fighter_sapm            float64\n",
            "fighter_str_def_%       float64\n",
            "fighter_td_avg          float64\n",
            "fighter_td_acc_%        float64\n",
            "fighter_td_def_%        float64\n",
            "fighter_sub_avg         float64\n",
            "fighter_url              object\n",
            "avg_knockdowns          float64\n",
            "avg_sig_strike_atts     float64\n",
            "avg_sig_strikes         float64\n",
            "avg_tot_strike_atts     float64\n",
            "avg_tot_strikes         float64\n",
            "avg_takedown_atts       float64\n",
            "avg_takedowns           float64\n",
            "avg_clinch_atts         float64\n",
            "avg_clinchs             float64\n",
            "avg_ctrl_time           float64\n",
            "avg_total_fight_time    float64\n",
            "avg_submissions         float64\n",
            "avg_reversals           float64\n",
            "avg_head_strike_atts    float64\n",
            "avg_head_strikes        float64\n",
            "avg_body_strike_atts    float64\n",
            "avg_body_strikes        float64\n",
            "avg_leg_strike_atts     float64\n",
            "avg_leg_strikes         float64\n",
            "avg_dist_strike_atts    float64\n",
            "avg_dist_strikes        float64\n",
            "avg_ground_atts         float64\n",
            "avg_grounds             float64\n",
            "dtype: object\n",
            "\n",
            "Missing values:\n",
            "fighter_id                 0\n",
            "fighter_name               0\n",
            "fighter_dob              755\n",
            "fighter_height_cm        304\n",
            "fighter_weight_lbs        86\n",
            "fighter_reach_cm        1928\n",
            "fighter_stance           826\n",
            "fighter_wins               0\n",
            "fighter_losses             0\n",
            "fighter_draws              0\n",
            "fighter_slpm               0\n",
            "fighter_str_acc_%          0\n",
            "fighter_sapm               0\n",
            "fighter_str_def_%          0\n",
            "fighter_td_avg             0\n",
            "fighter_td_acc_%           0\n",
            "fighter_td_def_%           0\n",
            "fighter_sub_avg            0\n",
            "fighter_url                0\n",
            "avg_knockdowns             0\n",
            "avg_sig_strike_atts        0\n",
            "avg_sig_strikes            0\n",
            "avg_tot_strike_atts        0\n",
            "avg_tot_strikes            0\n",
            "avg_takedown_atts          0\n",
            "avg_takedowns              0\n",
            "avg_clinch_atts            0\n",
            "avg_clinchs                0\n",
            "avg_ctrl_time            136\n",
            "avg_total_fight_time       0\n",
            "avg_submissions            0\n",
            "avg_reversals              0\n",
            "avg_head_strike_atts       0\n",
            "avg_head_strikes           0\n",
            "avg_body_strike_atts       0\n",
            "avg_body_strikes           0\n",
            "avg_leg_strike_atts        0\n",
            "avg_leg_strikes            0\n",
            "avg_dist_strike_atts       0\n",
            "avg_dist_strikes           0\n",
            "avg_ground_atts            0\n",
            "avg_grounds                0\n",
            "dtype: int64\n",
            "Filled fighter_height_cm with median: 177.80\n",
            "Filled fighter_weight_lbs with median: 168.00\n",
            "Filled fighter_reach_cm with median: 182.88\n",
            "Filled avg_ctrl_time with median: 16.00\n",
            "Filled fighter_dob with: 1987-01-21\n",
            "Filled fighter_stance with: Orthodox\n",
            "\n",
            "Fighter columns identified: ['f1_id', 'f2_id', 'f1_name', 'f2_name', 'f1_age_during', 'f2_age_during', 'f1_height_cm', 'f2_height_cm', 'f1_knockdowns', 'f2_knockdowns', 'f1_sig_strike_atts', 'f2_sig_strike_atts', 'f1_sig_strikes', 'f2_sig_strikes', 'f1_tot_strike_atts', 'f2_tot_strike_atts', 'f1_tot_strikes', 'f2_tot_strikes', 'f1_takedown_atts', 'f2_takedown_atts', 'f1_takedowns', 'f2_takedowns', 'f1_submissions', 'f2_submissions', 'f1_reversals', 'f2_reversals', 'f1_ctrl_time', 'f2_ctrl_time', 'f1_head_strike_atts', 'f2_head_strike_atts', 'f1_head_strikes', 'f2_head_strikes', 'f1_body_strike_atts', 'f2_body_strike_atts', 'f1_body_strikes', 'f2_body_strikes', 'f1_leg_strike_atts', 'f2_leg_strike_atts', 'f1_leg_strikes', 'f2_leg_strikes', 'f1_dist_strike_atts', 'f2_dist_strike_atts', 'f1_dist_strikes', 'f2_dist_strikes', 'f1_clinch_atts', 'f2_clinch_atts', 'f1_clinchs', 'f2_clinchs', 'f1_ground_atts', 'f2_ground_atts', 'f1_grounds', 'f2_grounds', 'f1_total_fight_time', 'f2_total_fight_time']\n",
            "\n",
            "============================================================\n",
            "MERGING FIGHTER AVERAGES\n",
            "============================================================\n",
            "Using f1_name_col: f1_name, f2_name_col: f2_name\n",
            "Using fighters name column: fighter_name\n",
            "After merge, shape: (5930, 146)\n",
            "Merge success rate f1: 100.00%\n",
            "Merge success rate f2: 100.00%\n",
            "\n",
            "============================================================\n",
            "BUILDING PRE-FIGHT FEATURES\n",
            "============================================================\n",
            "\n",
            "Target distribution:\n",
            "y_winner\n",
            "1    3366\n",
            "0    2564\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Final modeling dataset:\n",
            "  Features: 15\n",
            "  Samples: 5930\n",
            "  Target distribution: {1: 3366, 0: 2564}\n",
            "\n",
            "============================================================\n",
            "EXPLORATORY DATA ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Summary Statistics of Key Features:\n",
            "          age_diff  height_diff   reach_diff    slpm_diff    sapm_diff  \\\n",
            "count  5930.000000  5930.000000  5930.000000  5930.000000  5930.000000   \n",
            "mean      0.617538     0.002142     0.133639     0.049037    -0.164658   \n",
            "std       5.259285     6.423326     8.430204     1.613714     1.573879   \n",
            "min     -22.000000   -22.860000   -30.480000    -8.990000   -12.000000   \n",
            "25%      -3.000000    -5.080000    -5.080000    -0.990000    -1.080000   \n",
            "50%       1.000000     0.000000     0.000000     0.040000    -0.150000   \n",
            "75%       4.000000     5.080000     5.080000     1.100000     0.840000   \n",
            "max      25.000000    33.020000    35.560000     7.650000    12.640000   \n",
            "\n",
            "       str_acc_diff  str_def_diff  td_avg_diff  td_acc_diff  td_def_diff  \n",
            "count   5930.000000   5930.000000  5930.000000  5930.000000  5930.000000  \n",
            "mean       0.003929      0.011035     0.108133     0.013895     0.022120  \n",
            "std        0.101235      0.095466     1.745988     0.262146     0.278315  \n",
            "min       -0.530000     -0.620000    -8.470000    -1.000000    -1.000000  \n",
            "25%       -0.060000     -0.050000    -0.870000    -0.140000    -0.150000  \n",
            "50%        0.000000      0.010000     0.080000     0.010000     0.020000  \n",
            "75%        0.070000      0.070000     1.100000     0.170000     0.190000  \n",
            "max        0.520000      0.580000     8.930000     1.000000     1.000000  \n",
            "\n",
            "Saved feature_distributions.png\n",
            "Saved correlation_matrix.png\n",
            "\n",
            "Win Rates by Weight Class:\n",
            "                                                    win_rate  count\n",
            "weight_class                                                       \n",
            "Lightweight Bout                                    0.566017    924\n",
            "Welterweight Bout                                   0.557225    865\n",
            "Featherweight Bout                                  0.572917    672\n",
            "Middleweight Bout                                   0.551360    662\n",
            "Bantamweight Bout                                   0.562295    610\n",
            "...                                                      ...    ...\n",
            "Ultimate Fighter China Featherweight Tournament...  1.000000      1\n",
            "Ultimate Fighter Brazil 4 Lightweight Tournamen...  1.000000      1\n",
            "Ultimate Fighter Latin America Featherweight To...  1.000000      1\n",
            "Ultimate Fighter Latin America 3 Lightweight To...  1.000000      1\n",
            "Ultimate Fighter Latin America Bantamweight Tou...  1.000000      1\n",
            "\n",
            "[71 rows x 2 columns]\n",
            "\n",
            "Win Rates by Stance Matchup:\n",
            "                      win_rate  count\n",
            "stance_matchup                       \n",
            "orthodox_vs_orthodox  0.568058   3306\n",
            "orthodox_vs_southpaw  0.538642    854\n",
            "southpaw_vs_orthodox  0.586619    837\n",
            "orthodox_vs_switch    0.515901    283\n",
            "southpaw_vs_southpaw  0.610656    244\n",
            "switch_vs_orthodox    0.557018    228\n",
            "southpaw_vs_switch    0.626667     75\n",
            "switch_vs_southpaw    0.695652     69\n",
            "switch_vs_switch      0.588235     34\n",
            "\n",
            "Win Rates by Reach Advantage:\n",
            "                    win_rate  count\n",
            "reach_advantage                    \n",
            "Large Disadvantage  0.556624   1872\n",
            "Small Disadvantage  0.557976   1423\n",
            "Small Advantage     0.547297    740\n",
            "Large Advantage     0.593668   1895\n",
            "\n",
            "Train set: 4744 samples\n",
            "Validation set: 1186 samples\n",
            "Train target distribution:\n",
            "y_winner\n",
            "1    2693\n",
            "0    2051\n",
            "Name: count, dtype: int64\n",
            "Validation target distribution:\n",
            "y_winner\n",
            "1    673\n",
            "0    513\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Numeric features (11): ['td_acc_diff', 'age_diff', 'str_def_diff', 'td_def_diff', 'slpm_diff', 'reach_diff', 'sub_avg_diff', 'height_diff', 'td_avg_diff', 'str_acc_diff', 'sapm_diff']\n",
            "Categorical features (4): ['stance_matchup', 'stance_f2', 'weight_class', 'stance_f1']\n",
            "\n",
            "============================================================\n",
            "TRAINING MODELS\n",
            "============================================================\n",
            "\n",
            "[1/5] Training Logistic Regression...\n",
            "[2/5] Training Decision Tree...\n",
            "[3/5] Training Random Forest...\n",
            "[4/5] Training Gradient Boosting...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-15 02:52:30,638] A new study created in memory with name: xgboost_optimization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5/5] Training XGBoost with Optuna tuning...\n",
            "  Running Optuna optimization (50 trials)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6abffae2c1bf4f8f93996f0ebbc4de0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-11-15 02:52:36,151] Trial 0 finished with value: 0.6902594121103081 and parameters: {'n_estimators': 650, 'max_depth': 6, 'learning_rate': 0.03657350149013256, 'subsample': 0.5086145995253384, 'colsample_bytree': 0.6615458050256791, 'min_child_weight': 4, 'gamma': 0.00015280069974534825}. Best is trial 0 with value: 0.6902594121103081.\n",
            "[I 2025-11-15 02:52:45,625] Trial 1 finished with value: 0.695913268558028 and parameters: {'n_estimators': 700, 'max_depth': 7, 'learning_rate': 0.0170889791221588, 'subsample': 0.8478973929379439, 'colsample_bytree': 0.6234731169796359, 'min_child_weight': 3, 'gamma': 1.3357562540320559e-06}. Best is trial 1 with value: 0.695913268558028.\n",
            "[I 2025-11-15 02:52:49,841] Trial 2 finished with value: 0.6763613800644064 and parameters: {'n_estimators': 600, 'max_depth': 5, 'learning_rate': 0.09975949301873742, 'subsample': 0.7735288788303628, 'colsample_bytree': 0.8521461980035168, 'min_child_weight': 10, 'gamma': 5.319937221439926e-07}. Best is trial 1 with value: 0.695913268558028.\n",
            "[I 2025-11-15 02:52:55,651] Trial 3 finished with value: 0.7151661814465589 and parameters: {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.011781624439949328, 'subsample': 0.8697163788461042, 'colsample_bytree': 0.9423922249702421, 'min_child_weight': 3, 'gamma': 2.4788281882177635e-08}. Best is trial 3 with value: 0.7151661814465589.\n",
            "[I 2025-11-15 02:53:00,109] Trial 4 finished with value: 0.6976089266494345 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.02604215950371754, 'subsample': 0.7563681767545074, 'colsample_bytree': 0.7504902496918066, 'min_child_weight': 10, 'gamma': 0.0007359084769988927}. Best is trial 3 with value: 0.7151661814465589.\n",
            "[I 2025-11-15 02:53:07,441] Trial 5 finished with value: 0.6696769103856098 and parameters: {'n_estimators': 550, 'max_depth': 10, 'learning_rate': 0.20435127308964512, 'subsample': 0.9732843996533687, 'colsample_bytree': 0.559580989708071, 'min_child_weight': 6, 'gamma': 3.247258586510963e-07}. Best is trial 3 with value: 0.7151661814465589.\n",
            "[I 2025-11-15 02:53:12,065] Trial 6 finished with value: 0.6641192110924485 and parameters: {'n_estimators': 700, 'max_depth': 4, 'learning_rate': 0.12605353242173448, 'subsample': 0.5171316024781194, 'colsample_bytree': 0.8566775501123576, 'min_child_weight': 4, 'gamma': 1.521970141733285e-07}. Best is trial 3 with value: 0.7151661814465589.\n",
            "[I 2025-11-15 02:53:13,349] Trial 7 finished with value: 0.6830405723836623 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.14793325950567318, 'subsample': 0.5302566668369557, 'colsample_bytree': 0.6440361340873846, 'min_child_weight': 8, 'gamma': 5.810883659491531e-08}. Best is trial 3 with value: 0.7151661814465589.\n",
            "[I 2025-11-15 02:53:15,034] Trial 8 finished with value: 0.7137361155300752 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.0184380974154954, 'subsample': 0.6865450033302782, 'colsample_bytree': 0.8201479421501279, 'min_child_weight': 6, 'gamma': 1.5160157933638439e-05}. Best is trial 3 with value: 0.7151661814465589.\n",
            "[I 2025-11-15 02:53:17,014] Trial 9 finished with value: 0.7206997466663612 and parameters: {'n_estimators': 150, 'max_depth': 8, 'learning_rate': 0.012325036642591743, 'subsample': 0.7117592603911918, 'colsample_bytree': 0.6545642138776404, 'min_child_weight': 8, 'gamma': 0.6887747515908279}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:53:26,427] Trial 10 finished with value: 0.6805640070519562 and parameters: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.05766758380402252, 'subsample': 0.6397947047220106, 'colsample_bytree': 0.5004384378672107, 'min_child_weight': 1, 'gamma': 0.6408466479886495}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:53:31,128] Trial 11 finished with value: 0.704079715170026 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.01160655990391888, 'subsample': 0.8871212929796326, 'colsample_bytree': 0.9676450978534449, 'min_child_weight': 8, 'gamma': 0.9913462121888127}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:53:41,402] Trial 12 finished with value: 0.7068506018247843 and parameters: {'n_estimators': 350, 'max_depth': 8, 'learning_rate': 0.01072546019330342, 'subsample': 0.851102185933702, 'colsample_bytree': 0.9959058046249646, 'min_child_weight': 1, 'gamma': 0.007272408883409992}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:53:42,851] Trial 13 finished with value: 0.7007928748119865 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.0491397201536157, 'subsample': 0.9989042880087186, 'colsample_bytree': 0.7214840637376481, 'min_child_weight': 8, 'gamma': 0.016615784713804517}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:53:50,278] Trial 14 finished with value: 0.7007654734335138 and parameters: {'n_estimators': 350, 'max_depth': 8, 'learning_rate': 0.018379955660634936, 'subsample': 0.6518232079559482, 'colsample_bytree': 0.9267841528104535, 'min_child_weight': 3, 'gamma': 1.0359717989450182e-08}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:53:54,258] Trial 15 finished with value: 0.7085417662378698 and parameters: {'n_estimators': 250, 'max_depth': 9, 'learning_rate': 0.010096383689870795, 'subsample': 0.9123994653735173, 'colsample_bytree': 0.7591154726078625, 'min_child_weight': 7, 'gamma': 1.411255675385403e-05}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:54:00,482] Trial 16 finished with value: 0.6982033904084899 and parameters: {'n_estimators': 450, 'max_depth': 6, 'learning_rate': 0.029383152616404406, 'subsample': 0.7981722947329679, 'colsample_bytree': 0.9220173316930692, 'min_child_weight': 5, 'gamma': 0.018528774765805042}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:54:19,163] Trial 17 finished with value: 0.6945555350966818 and parameters: {'n_estimators': 900, 'max_depth': 10, 'learning_rate': 0.015486582886450358, 'subsample': 0.706534194976823, 'colsample_bytree': 0.7082409125276513, 'min_child_weight': 2, 'gamma': 4.679390030461274e-06}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:54:20,305] Trial 18 finished with value: 0.7034106754890889 and parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.06483034376648848, 'subsample': 0.5947275622931133, 'colsample_bytree': 0.8005944013584789, 'min_child_weight': 9, 'gamma': 0.11137080831944181}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:54:27,120] Trial 19 finished with value: 0.6962530769228221 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.02298380115854027, 'subsample': 0.8159246466048959, 'colsample_bytree': 0.5739796383317715, 'min_child_weight': 5, 'gamma': 0.0010968453065994064}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:54:28,321] Trial 20 finished with value: 0.6769171152192968 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.2877899340723743, 'subsample': 0.9259699435463041, 'colsample_bytree': 0.8995621714888402, 'min_child_weight': 7, 'gamma': 9.912756721661644e-05}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:54:30,876] Trial 21 finished with value: 0.713392968355433 and parameters: {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.014130183632811592, 'subsample': 0.7053206285829384, 'colsample_bytree': 0.8103115547138265, 'min_child_weight': 6, 'gamma': 1.619349872869126e-05}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:54:32,600] Trial 22 finished with value: 0.7120843703176103 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.020503804845451695, 'subsample': 0.7057089853134012, 'colsample_bytree': 0.8645169026421905, 'min_child_weight': 7, 'gamma': 4.1636359866647664e-08}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:54:36,061] Trial 23 finished with value: 0.6979600515770364 and parameters: {'n_estimators': 250, 'max_depth': 9, 'learning_rate': 0.036228544778912374, 'subsample': 0.6501169567109654, 'colsample_bytree': 0.6901093808005365, 'min_child_weight': 4, 'gamma': 2.315119755923319e-06}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:54:41,117] Trial 24 finished with value: 0.712253429991105 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.014056755703759577, 'subsample': 0.7314777352792202, 'colsample_bytree': 0.7904827581171184, 'min_child_weight': 6, 'gamma': 7.817189806302951e-05}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:54:45,221] Trial 25 finished with value: 0.7067191897875433 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.012222830601040173, 'subsample': 0.5880911482016348, 'colsample_bytree': 0.9556792201817879, 'min_child_weight': 9, 'gamma': 0.0006207547787201724}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:54:47,704] Trial 26 finished with value: 0.7020823523699558 and parameters: {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.032578928218661984, 'subsample': 0.6726076679536412, 'colsample_bytree': 0.5953533141444612, 'min_child_weight': 3, 'gamma': 1.2484704359121706e-08}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:54:49,175] Trial 27 finished with value: 0.7144312764256795 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.017773974038575134, 'subsample': 0.5955950433757183, 'colsample_bytree': 0.8857305894330842, 'min_child_weight': 5, 'gamma': 0.0049032949946408045}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:54:59,974] Trial 28 finished with value: 0.6909647448824263 and parameters: {'n_estimators': 850, 'max_depth': 6, 'learning_rate': 0.023741550217034866, 'subsample': 0.586281940245359, 'colsample_bytree': 0.8914524294900645, 'min_child_weight': 2, 'gamma': 0.12388800335579506}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:55:02,800] Trial 29 finished with value: 0.7121328366142736 and parameters: {'n_estimators': 250, 'max_depth': 7, 'learning_rate': 0.013753678796216239, 'subsample': 0.5646528224604628, 'colsample_bytree': 0.6837488947335812, 'min_child_weight': 5, 'gamma': 0.1385931930327422}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:55:09,095] Trial 30 finished with value: 0.686524742416655 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.041670871994575864, 'subsample': 0.621152406554584, 'colsample_bytree': 0.9950279138008864, 'min_child_weight': 4, 'gamma': 0.0056466177089426585}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:55:11,364] Trial 31 finished with value: 0.7097010504941421 and parameters: {'n_estimators': 150, 'max_depth': 8, 'learning_rate': 0.018745248028078462, 'subsample': 0.6814756581737492, 'colsample_bytree': 0.8321434745069206, 'min_child_weight': 5, 'gamma': 2.0760798215085525e-05}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:55:13,097] Trial 32 finished with value: 0.7163504790000146 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.01680441955864833, 'subsample': 0.7853040388016509, 'colsample_bytree': 0.888991266533302, 'min_child_weight': 3, 'gamma': 0.0016613884438843396}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:55:16,098] Trial 33 finished with value: 0.7102375943296029 and parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.016142543895487204, 'subsample': 0.835600204649802, 'colsample_bytree': 0.9507302816292604, 'min_child_weight': 3, 'gamma': 0.0024867606154634677}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:55:19,595] Trial 34 finished with value: 0.6939887211238006 and parameters: {'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.08029215059399517, 'subsample': 0.7855579542516572, 'colsample_bytree': 0.8886379940205144, 'min_child_weight': 2, 'gamma': 0.0002917580407782694}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:55:22,628] Trial 35 finished with value: 0.7003339686303801 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.02713559304500365, 'subsample': 0.7586160647451761, 'colsample_bytree': 0.7670985243285517, 'min_child_weight': 3, 'gamma': 0.028493775729622903}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:55:33,531] Trial 36 finished with value: 0.7040124490361259 and parameters: {'n_estimators': 750, 'max_depth': 7, 'learning_rate': 0.010030989097469308, 'subsample': 0.8796865520810359, 'colsample_bytree': 0.9236860720381431, 'min_child_weight': 4, 'gamma': 0.0025424413999153178}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:55:38,418] Trial 37 finished with value: 0.7016441980107633 and parameters: {'n_estimators': 600, 'max_depth': 5, 'learning_rate': 0.020264387731499793, 'subsample': 0.7364098256688137, 'colsample_bytree': 0.8613631197567352, 'min_child_weight': 2, 'gamma': 0.05268733168396192}. Best is trial 9 with value: 0.7206997466663612.\n",
            "[I 2025-11-15 02:55:40,133] Trial 38 finished with value: 0.7243738032375328 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.013124991540191248, 'subsample': 0.9451957993386948, 'colsample_bytree': 0.6376471554559738, 'min_child_weight': 4, 'gamma': 0.0003048567270705461}. Best is trial 38 with value: 0.7243738032375328.\n",
            "[I 2025-11-15 02:55:45,777] Trial 39 finished with value: 0.7130046193823446 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.012055008207333887, 'subsample': 0.9544655699478707, 'colsample_bytree': 0.6385405563317955, 'min_child_weight': 3, 'gamma': 0.00025048542281259553}. Best is trial 38 with value: 0.7243738032375328.\n",
            "[I 2025-11-15 02:55:50,133] Trial 40 finished with value: 0.7032652171631556 and parameters: {'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.014396376011480387, 'subsample': 0.9379299097963643, 'colsample_bytree': 0.606669397946818, 'min_child_weight': 4, 'gamma': 5.76994443400532e-07}. Best is trial 38 with value: 0.7243738032375328.\n",
            "[I 2025-11-15 02:55:51,622] Trial 41 finished with value: 0.7215138837816905 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.016594563631620686, 'subsample': 0.8703794313358724, 'colsample_bytree': 0.6671419182025174, 'min_child_weight': 4, 'gamma': 5.011358155414583e-05}. Best is trial 38 with value: 0.7243738032375328.\n",
            "[I 2025-11-15 02:55:53,735] Trial 42 finished with value: 0.718049626070105 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.012570914563393949, 'subsample': 0.8719205993403607, 'colsample_bytree': 0.668664573155039, 'min_child_weight': 4, 'gamma': 7.628979208606394e-05}. Best is trial 38 with value: 0.7243738032375328.\n",
            "[I 2025-11-15 02:55:55,773] Trial 43 finished with value: 0.7109087013561282 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.02240808354260286, 'subsample': 0.9023625970453671, 'colsample_bytree': 0.6669293622102884, 'min_child_weight': 4, 'gamma': 2.9869477920792325e-05}. Best is trial 38 with value: 0.7243738032375328.\n",
            "[I 2025-11-15 02:55:59,122] Trial 44 finished with value: 0.7258559333988233 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.012547687978573332, 'subsample': 0.8613028333180323, 'colsample_bytree': 0.5440314080183747, 'min_child_weight': 10, 'gamma': 6.062647224663016e-05}. Best is trial 44 with value: 0.7258559333988233.\n",
            "[I 2025-11-15 02:56:01,932] Trial 45 finished with value: 0.7145444032878527 and parameters: {'n_estimators': 250, 'max_depth': 8, 'learning_rate': 0.012999348699501544, 'subsample': 0.8593476719959131, 'colsample_bytree': 0.5217038056478788, 'min_child_weight': 10, 'gamma': 4.314410392102718e-05}. Best is trial 44 with value: 0.7258559333988233.\n",
            "[I 2025-11-15 02:56:03,052] Trial 46 finished with value: 0.728931261676809 and parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.011612351484450603, 'subsample': 0.9696746660941791, 'colsample_bytree': 0.556290087697176, 'min_child_weight': 9, 'gamma': 5.030009477588229e-06}. Best is trial 46 with value: 0.728931261676809.\n",
            "[I 2025-11-15 02:56:04,053] Trial 47 finished with value: 0.7293007867059512 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.01582754743449501, 'subsample': 0.9981010196181461, 'colsample_bytree': 0.5360403860657196, 'min_child_weight': 9, 'gamma': 6.408140878613625e-06}. Best is trial 47 with value: 0.7293007867059512.\n",
            "[I 2025-11-15 02:56:05,036] Trial 48 finished with value: 0.7310992779384942 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.01085699646438163, 'subsample': 0.9968410386298209, 'colsample_bytree': 0.548579530725926, 'min_child_weight': 9, 'gamma': 6.9716806761867186e-06}. Best is trial 48 with value: 0.7310992779384942.\n",
            "[I 2025-11-15 02:56:06,220] Trial 49 finished with value: 0.6959195264868974 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.12772917035683756, 'subsample': 0.9945880796195832, 'colsample_bytree': 0.5398106286280827, 'min_child_weight': 9, 'gamma': 5.929750161660938e-06}. Best is trial 48 with value: 0.7310992779384942.\n",
            "  Best F1 score: 0.7311\n",
            "  Best parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.01085699646438163, 'subsample': 0.9968410386298209, 'colsample_bytree': 0.548579530725926, 'min_child_weight': 9, 'gamma': 6.9716806761867186e-06}\n",
            "\n",
            "============================================================\n",
            "MODEL EVALUATION\n",
            "============================================================\n",
            "\n",
            "log_reg:\n",
            "----------------------------------------\n",
            "Train - Accuracy: 0.6594, Precision: 0.6763, Recall: 0.7672, F1: 0.7189\n",
            "Val   - Accuracy: 0.6450, Precision: 0.6620, Recall: 0.7652, F1: 0.7099\n",
            "  OK: Good generalization\n",
            "\n",
            "Confusion Matrix (Validation):\n",
            "[[250 263]\n",
            " [158 515]]\n",
            "\n",
            "decision_tree:\n",
            "----------------------------------------\n",
            "Train - Accuracy: 0.7949, Precision: 0.7978, Recall: 0.8556, F1: 0.8257\n",
            "Val   - Accuracy: 0.5944, Precision: 0.6297, Recall: 0.6924, F1: 0.6596\n",
            "  WARNING: High train but low val -> Overfitting detected\n",
            "\n",
            "Confusion Matrix (Validation):\n",
            "[[239 274]\n",
            " [207 466]]\n",
            "\n",
            "random_forest:\n",
            "----------------------------------------\n",
            "Train - Accuracy: 0.8116, Precision: 0.7812, Recall: 0.9280, F1: 0.8483\n",
            "Val   - Accuracy: 0.6560, Precision: 0.6525, Recall: 0.8425, F1: 0.7354\n",
            "  WARNING: High train but low val -> Overfitting detected\n",
            "\n",
            "Confusion Matrix (Validation):\n",
            "[[211 302]\n",
            " [106 567]]\n",
            "\n",
            "gradient_boosting:\n",
            "----------------------------------------\n",
            "Train - Accuracy: 0.8084, Precision: 0.7987, Recall: 0.8856, F1: 0.8399\n",
            "Val   - Accuracy: 0.6425, Precision: 0.6645, Recall: 0.7474, F1: 0.7035\n",
            "  WARNING: High train but low val -> Overfitting detected\n",
            "\n",
            "Confusion Matrix (Validation):\n",
            "[[259 254]\n",
            " [170 503]]\n",
            "\n",
            "xgboost_optuna:\n",
            "----------------------------------------\n",
            "Train - Accuracy: 0.6775, Precision: 0.6531, Recall: 0.9213, F1: 0.7643\n",
            "Val   - Accuracy: 0.6476, Precision: 0.6300, Recall: 0.9183, F1: 0.7473\n",
            "  OK: Good generalization\n",
            "\n",
            "Confusion Matrix (Validation):\n",
            "[[150 363]\n",
            " [ 55 618]]\n",
            "\n",
            "============================================================\n",
            "MODEL COMPARISON SUMMARY\n",
            "============================================================\n",
            "       model_name  train_accuracy  train_f1  val_accuracy  val_precision  val_recall   val_f1\n",
            "   xgboost_optuna        0.677487  0.764325      0.647555       0.629969    0.918276 0.747279\n",
            "    random_forest        0.811551  0.848269      0.655987       0.652474    0.842496 0.735409\n",
            "          log_reg        0.659359  0.718859      0.645025       0.661954    0.765230 0.709855\n",
            "gradient_boosting        0.808390  0.839937      0.642496       0.664465    0.747400 0.703497\n",
            "    decision_tree        0.794899  0.825658      0.594435       0.629730    0.692422 0.659590\n",
            "\n",
            "============================================================\n",
            "MODEL DIAGNOSIS\n",
            "============================================================\n",
            "  random_forest: Overfitting (train=0.812, val=0.656)\n",
            "  gradient_boosting: Overfitting (train=0.808, val=0.642)\n",
            "  decision_tree: Overfitting (train=0.795, val=0.594)\n",
            "\n",
            "============================================================\n",
            "SELECTED BEST MODEL: xgboost_optuna\n",
            "============================================================\n",
            "Validation F1 Score: 0.7473\n",
            "Validation Accuracy: 0.6476\n",
            "\n",
            "============================================================\n",
            "EXTERNAL TEST SET EVALUATION\n",
            "============================================================\n",
            "\n",
            "Loading external test dataset: ufc_fight_test - Sheet1.csv\n",
            "No header row detected, using training CSV column structure...\n",
            "Warning: External test file ufc_fight_test - Sheet1.csv not found. Skipping external evaluation.\n",
            "\n",
            "============================================================\n",
            "PREDICTING SPECIFIC FIGHTS\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Main Event: Jack Della Maddalena vs Islam Makhachev\n",
            "Weight Class: Welterweight\n",
            "============================================================\n",
            "\n",
            "Detailed Feature Breakdown:\n",
            "------------------------------------------------------------\n",
            "  Reach Difference                   :     7.62\n",
            "  Height Difference                  :     2.54\n",
            "  Age Difference                     :     0.00\n",
            "  Strikes Landed/Min Difference      :     4.09\n",
            "  Striking Accuracy Difference       :    -0.06\n",
            "  Takedown Average Difference        :    -2.98\n",
            "  Takedown Defense Difference        :    -0.20\n",
            "\n",
            "  Stance Matchup: switch_vs_southpaw\n",
            "\n",
            "============================================================\n",
            "PREDICTION RESULTS:\n",
            "============================================================\n",
            "Jack Della Maddalena          : 51.72% win probability\n",
            "Islam Makhachev               : 48.28% win probability\n",
            "\n",
            "Predicted Winner: Jack Della Maddalena\n",
            "\n",
            "============================================================\n",
            "MODEL INTERPRETATION:\n",
            "============================================================\n",
            "\n",
            "Model favors Jack Della Maddalena with 51.7% win probability.\n",
            "\n",
            "Key advantages identified by the model:\n",
            "  1. Jack Della Maddalena has 7.6cm reach advantage\n",
            "  2. Jack Della Maddalena has 2.5cm height advantage\n",
            "  3. Islam Makhachev has superior takedown average (+2.98 per 15min)\n",
            "  4. Jack Della Maddalena lands more strikes per minute (+4.09)\n",
            "\n",
            "============================================================\n",
            "Co-main: Valentina Shevchenko vs Zhang Weili\n",
            "Weight Class: Women Flyweight\n",
            "============================================================\n",
            "\n",
            "Detailed Feature Breakdown:\n",
            "------------------------------------------------------------\n",
            "  Reach Difference                   :     7.62\n",
            "  Height Difference                  :     2.54\n",
            "  Age Difference                     :     0.00\n",
            "  Strikes Landed/Min Difference      :    -2.50\n",
            "  Striking Accuracy Difference       :    -0.01\n",
            "  Takedown Average Difference        :     0.23\n",
            "  Takedown Defense Difference        :     0.21\n",
            "\n",
            "  Stance Matchup: southpaw_vs_switch\n",
            "\n",
            "============================================================\n",
            "PREDICTION RESULTS:\n",
            "============================================================\n",
            "Valentina Shevchenko          : 58.05% win probability\n",
            "Zhang Weili                   : 41.95% win probability\n",
            "\n",
            "Predicted Winner: Valentina Shevchenko\n",
            "\n",
            "============================================================\n",
            "MODEL INTERPRETATION:\n",
            "============================================================\n",
            "\n",
            "Model favors Valentina Shevchenko with 58.0% win probability.\n",
            "\n",
            "Key advantages identified by the model:\n",
            "  1. Valentina Shevchenko has 7.6cm reach advantage\n",
            "  2. Valentina Shevchenko has 2.5cm height advantage\n",
            "  3. Zhang Weili lands more strikes per minute (+2.50)\n",
            "\n",
            "============================================================\n",
            "PREDICTIONS SUMMARY\n",
            "============================================================\n",
            "            fighter1        fighter2    weight_class  p_f1_win  p_f2_win     predicted_winner\n",
            "Jack Della Maddalena Islam Makhachev    Welterweight  0.517242  0.482758 Jack Della Maddalena\n",
            "Valentina Shevchenko     Zhang Weili Women Flyweight  0.580463  0.419537 Valentina Shevchenko\n",
            "\n",
            "============================================================\n",
            "PIPELINE COMPLETE\n",
            "============================================================\n",
            "\n",
            "All predictions have been generated and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kt6N0VgZbCd8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6abffae2c1bf4f8f93996f0ebbc4de0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7359bee6a9045ecaddb3d1adc362f32",
              "IPY_MODEL_1aac54293d5f460ca8c343b6060df665",
              "IPY_MODEL_d0eff80aca9443b8a12002f0e00ff3ac"
            ],
            "layout": "IPY_MODEL_04fc97ced4a14512832002a20d6fe19f"
          }
        },
        "f7359bee6a9045ecaddb3d1adc362f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d850d41ae11e49ac82869437dae2d6e0",
            "placeholder": "​",
            "style": "IPY_MODEL_769434084e5e4c92951888e7d1683797",
            "value": "Best trial: 48. Best value: 0.731099: 100%"
          }
        },
        "1aac54293d5f460ca8c343b6060df665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0147b56dadac4b4da6899ed30d1dfe2e",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c27eff96be7148b48b4922c190283930",
            "value": 50
          }
        },
        "d0eff80aca9443b8a12002f0e00ff3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71dc03a08b854cf390f1d0d7a4d006e0",
            "placeholder": "​",
            "style": "IPY_MODEL_7dd61ff97dd84caf8a533f8e1528570f",
            "value": " 50/50 [03:35&lt;00:00,  1.53s/it]"
          }
        },
        "04fc97ced4a14512832002a20d6fe19f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d850d41ae11e49ac82869437dae2d6e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "769434084e5e4c92951888e7d1683797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0147b56dadac4b4da6899ed30d1dfe2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c27eff96be7148b48b4922c190283930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71dc03a08b854cf390f1d0d7a4d006e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd61ff97dd84caf8a533f8e1528570f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}